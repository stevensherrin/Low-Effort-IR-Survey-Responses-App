[{"name":"app.R","content":"library(shiny)\r\nlibrary(dplyr)\r\nlibrary(reactable)\r\nlibrary(bslib)\r\n\r\n# Source the helper functions\r\nsource(\"helpers.R\")\r\nsource(\"library_functions.R\")\r\n\r\n# Downloading issue in Chrome. Workaround for Chromium Issue 468227\r\ndownloadButton <- function(...) {\r\n  tag <- shiny::downloadButton(...)\r\n  tag$attribs$download <- NULL\r\n  tag\r\n}\r\n\r\n# UI definition\r\nui <- fluidPage(\r\n  theme = bslib::bs_theme(\r\n    primary = \"#007BFF\",\r\n    secondary = \"#6C757D\"\r\n  ),\r\n  tags$head(\r\n    tags$style(HTML(\"\r\n      .shiny-input-container {  \r\n        font-family: 'IBM Plex Sans', sans-serif;\r\n      }\r\n      .icon {\r\n        font-size: 24px;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .footer {\r\n        font-size: 12px;\r\n        color: #6C757D;\r\n        margin-top: 20px;\r\n        text-align: right;\r\n      }\r\n      .header {\r\n        display: flex;\r\n        align-items: center;\r\n        margin-bottom: 20px;\r\n      }\r\n      .header img {\r\n        margin-right: 10px;\r\n      }\r\n      .safety-icon {\r\n        font-size: 24px;\r\n        color: #28a745;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .overview-icon {\r\n        font-size: 24px;\r\n        color: #007BFF;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .main-title {\r\n        font-size: 36px;\r\n        font-weight: bold;\r\n        text-align: left;\r\n        margin-bottom: 20px;\r\n      }\r\n    \"))\r\n  ),\r\n  \r\n  # Main header with the title\r\n  div(\r\n    class = \"header\",\r\n    div(\r\n      style = \"background: linear-gradient(to right, #007BFF, #6C757D);\r\n              padding: 10px; border-radius: 8px; display: inline-block;\",\r\n      h1(\r\n        style = \"font-family: 'IBM Plex Sans', sans-serif;\r\n                 color: white; font-weight: bold;\r\n                 text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4);\",\r\n        \"Detecting Low-Effort IR Survey Responses\"\r\n      )\r\n    )\r\n  ),\r\n  \r\n  \r\n  \r\n  sidebarLayout(\r\n    sidebarPanel(\r\n      selectInput(\"surveySelect\", \"Select your survey\", \r\n                  choices = c(\"NSSE\" = \"National Survey of Student Engagement (NSSE)\")),\r\n      fileInput(\"file\", \"Upload the raw data file (.csv, .xlsx):\"),\r\n      actionButton(\"run\", \"Run\")#,\r\n      #downloadButton(\"downloadData\", \"Download Data\")\r\n    ),\r\n    mainPanel(\r\n      tabsetPanel(\r\n        tabPanel(\"Overview\",\r\n                 uiOutput(\"analysisCompleteOverview\"),\r\n                 HTML(\"<div style='margin-top: 20px;'>\r\n        <p><span class='overview-icon' style='font-size: 150%;'>&#128200;<\/span> This dashboard is a free tool designed to flag and remove low-effort responses on higher education surveys like the NSSE.<\/p>\r\n        <p><span class='safety-icon' style='font-size: 150%;'>&#128274;<\/span> This tool is deployed using <a href='https://shiny.posit.co/py/docs/shinylive.html' target='_blank'>ShinyLive<\/a>, ensuring your data are processed locally and remain secure.<\/p>\r\n        <p><span class='process-icon' style='font-size: 150%;'>&#128187;<\/span> How does this work? Import your <b>raw<\/b> data file for the survey provided by the organization running the survey - <a href='#' onclick='alert(\\\"Details on how to prepare your data file go here.\\\");'>click here for details<\/a>.<\/p>\r\n    <\/div>\")\r\n        ),\r\n        tabPanel(\"Summary\",\r\n                 tags$div(\r\n                   tags$br(),  # Add a line break here\r\n                   tags$h3(style = \"font-weight: bold;\", \"Survey Response Summary\"),\r\n                   tags$p(style = \"font-size: 18px; font-weight: bold; color: #2E86C1;\", uiOutput(\"summaryText\")),\r\n                   tags$br(), tags$br(),  # Add two line breaks here\r\n                   tags$h3(style = \"font-weight: bold;\", \"Summary Table\"),\r\n                   reactableOutput(\"summaryTable\")\r\n                 )\r\n        ),\r\n\r\n        tabPanel(\"Explore Data\",\r\n                 selectInput(\"dataViewSelect\", \"See Low-Effort Responses for:\",\r\n                             choices = c(\"Filter 1: Survey Duration\" = \"Completed survey in 3 minutes or less\",\r\n                                         \"Filter 2: Skipped Questions\" = \"Skipped over 25% of survey questions\",\r\n                                         \"Filter 3: Straightlined 15 Responses\" = \"Straightlined 15 Responses\",\r\n                                         \"Filters 4 & 5: Repeated Straightline Behavior\" = \"Repeated Straightline Behavior\",\r\n                                         \"Filter 6: Other Repetitive Behavior\" = \"Other Repetitive Behavior\",\r\n                                         \"Filter 7: Unrealistic Quantitative Responses\" = \"Unrealistic Quantitative Responses\")),\r\n                 HTML(\"<p><i>This table displays respondents who were flagged for this particular issue, suggesting a low-effort response.<\/i><\/p>\"),\r\n                 reactableOutput(\"individualExamplesTable\")\r\n        ),\r\n        tabPanel(\"Download Data\",\r\n                 HTML(\"<div style='margin-top: 20px;'>\r\n                        <h2>&#128190; Download Data<\/h2>\r\n                        <p>The 'Download Data' exports a file containing your raw data with the addition of new columns indicating if (and why) the respondent was flagged as a low-effort responder.<\/p>\r\n                      <\/div>\"),\r\n                 downloadButton(\"downloadData\", \"Download Data\")\r\n        ),\r\n        tabPanel(\"About\",\r\n                 HTML(\"<h2 style='font-weight: bold;'>About this Tool<\/h2>\r\n        <p>This is an 'opinionated' tool: it decides what responses qualify as 'low effort' or not based on subjectively selected criteria. Our tool uses a sequential screening method to exclude respondents whose behavior may suggest a low-effort response. The table above provides a summary of your results from the raw data file. <a href='methodology_link_here'>More details on the methodology can be found here.<\/a><\/p>\r\n        <p>You can view the source code at Steve's <a href='https://github.com/stevensherrin' target='_blank'>GitHub page<\/a>. You are allowed to use and improve it, but not for any commercial purposes.<\/p>\")\r\n        )\r\n        \r\n        \r\n      )\r\n    )\r\n  ),\r\n  div(class = \"footer\",\r\n      HTML(\"<p>This dashboard was created by <a href='https://www.linkedin.com/in/steven-sherrin' target='_blank'>Steven Sherrin<\/a>. Research was conducted by <a href='https://www.linkedin.com/in/ingerbergom' target='_blank'>Inger Bergom<\/a> (Harvard University) and <a href='https://www.linkedin.com/in/steven-sherrin' target='_blank'>Steven Sherrin<\/a> (Wentworth Institute of Technology).<\/p>\")\r\n  )\r\n)\r\n\r\n# Server logic\r\nserver <- function(input, output, session) {\r\n  data <- reactiveVal()\r\n  \r\n  \r\n  observeEvent(input$run, {\r\n    req(input$file)\r\n    \r\n    # Read the uploaded file\r\n    df <- read_uploaded_file(input$file)\r\n    \r\n    # Check for missing variables\r\n    missing_vars <- check_missing_vars(df)\r\n    \r\n    # Show screen if any variables are missing\r\n    if (length(missing_vars) > 0) {\r\n      showModal(modalDialog(\r\n        title = \"Missing Variables\",\r\n        paste(missing_vars, collapse = \", \"),\r\n        easyClose = TRUE,\r\n        footer = modalButton(\"OK\")\r\n      ))\r\n    }\r\n  })\r\n  \r\n  observeEvent(input$run, {\r\n    req(input$file)\r\n    \r\n    # Remove recoded or estimated variables not used in the analysis\r\n    df <- remove_recoded_vars(df)\r\n    \r\n    # Clean the uploaded data\r\n    df <- clean_data(df)\r\n    \r\n    # Identify careless responses\r\n    df <- identify_careless_responses(df)\r\n    \r\n    # Process the summary table data\r\n    summary_df <- calculate_summary(df)\r\n    data(summary_df)\r\n    \r\n    # Let user know analysis is complete\r\n    output$analysisCompleteOverview <- renderUI({\r\n      HTML(\"<h3 style='font-size: 16px; border: 1px dotted pink; padding: 10px; font-weight: bold;'><br>Analysis of your data is complete! To see a summary table of your results, go to 'Summary'. To see individual responses, go to 'Explore Data'. To download your data, go to 'Download Data'.<\/h3>\")\r\n    })\r\n    \r\n    output$analysisComplete <- renderUI({\r\n      HTML(\"<h3 style='font-size: 16px; border: 1px dotted pink; padding: 10px; font-weight: bold;'><br>Analysis of your data is complete! To see a summary table of your results, go to 'Summary'. To see individual responses, go to 'Explore Data'. To download your data, go to 'Download Data'.<\/h3>\")\r\n    })\r\n    \r\n    \r\n    # Render summary text\r\n    output$summaryText <- renderText({\r\n      max_val <- max(data()$`Total Remaining Respondents`)\r\n      min_val <- min(data()$`Total Remaining Respondents`)\r\n      filtered_out <- max_val - min_val\r\n      percent_flagged <- (filtered_out / max_val) * 100\r\n      paste0(\"You started with <b style='text-decoration: underline double;'>\", max_val, \"<\/b> respondents. After we searched for low-effort responses, we identified and removed <b style='text-decoration: underline double;'>\", \r\n             filtered_out, \"<\/b> respondents (<b style='text-decoration: underline double;'>\", round(percent_flagged, 1), \"% of total<\/b>). You now have <b style='text-decoration: underline double;'>\", min_val, \"<\/b> remaining responses. For details on why respondents were removed, see the table below. For methodology details, see About.\")\r\n    })\r\n    \r\n    \r\n    # Render summary table\r\n    output$summaryTable <- renderReactable({\r\n      req(data())\r\n      \r\n      modified_data <- data()[-1, ]  # Remove the first row\r\n      \r\n      reactable(\r\n        modified_data,\r\n        columns = list(\r\n          Criteria = colDef(\r\n            name = \"\",\r\n            cell = function(value) {\r\n              div(style = list(fontStyle = \"italic\"), value)\r\n            },\r\n            headerStyle = list(verticalAlign = \"top\"),  # Align header to bottom\r\n            minWidth = 350, maxWidth = 350\r\n          ),\r\n          `Total Remaining Respondents` = colDef(\r\n            name = \"Total Remaining Respondents\",\r\n            headerStyle = list(textAlign = \"center\"),\r\n            style = list(textAlign = \"center\"),\r\n            minWidth = 150, maxWidth = 150\r\n          ),\r\n          `Total Respondents Excluded` = colDef(\r\n            name = \"Number of Respondents Excluded due to this Step\",\r\n            headerStyle = list(textAlign = \"center\"),\r\n            style = list(textAlign = \"center\"),\r\n            minWidth = 150, maxWidth = 150\r\n          ),\r\n          `Percentage of Total Respondents Removed` = colDef(\r\n            name = \"Percent of Respondents Excluded due to this Step\",\r\n            headerStyle = list(textAlign = \"center\"),\r\n            format = colFormat(percent = TRUE, digits = 1),\r\n            style = list(textAlign = \"center\"),\r\n            minWidth = 150, maxWidth = 150\r\n            \r\n          )\r\n        ),\r\n        rowStyle = function(index) {\r\n          if (index == nrow(modified_data)) {\r\n            list(\r\n              background = \"darkred\",  # dark red background\r\n              color = \"white\",\r\n              fontWeight = \"bold\",\r\n              border = \"2px solid #cc0000\",  # border to further highlight\r\n              width = \"100%\"\r\n            )\r\n          } else {\r\n            NULL\r\n          }\r\n        }\r\n      )\r\n    })\r\n    \r\n    \r\n    \r\n    # output$diagram <- renderDiagrammeR({\r\n    #   generate_diagram(summary_df)\r\n    # })\r\n    \r\n    \r\n    # Render Explore Data table\r\n    output$individualExamplesTable <- renderReactable({\r\n      req(data()) # Ensure data is loaded\r\n      \r\n      if (input$dataViewSelect == \"Completed survey in 3 minutes or less\") {\r\n        process_individual_examples(df, \"Completed survey in 3 minutes or less\")\r\n        columns <- colnames(step_1_filtered)\r\n        \r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          if (col == \"Duration (minutes)\") {\r\n            colDef(\r\n              cell = function(value) {\r\n                if (!is.na(value) && value <= 3) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            )\r\n          } else {\r\n            colDef(\r\n              headerStyle = list(textAlign = \"center\"),\r\n              style = list(textAlign = \"center\")\r\n            )\r\n          }\r\n        }), columns)\r\n        \r\n        reactable(step_1_filtered, defaultPageSize = 10, columns = column_defs, \r\n                  style = list(width = \"75%\")) # Limit the width of the table because it's only two columns\r\n        \r\n      } else if (input$dataViewSelect == \"Skipped over 25% of survey questions\") {\r\n        process_individual_examples(df, \"Skipped over 25% of survey questions\")\r\n        columns <- colnames(step_2_filtered) # Get the column names of the data\r\n        \r\n        # Create a named list of column definitions\r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          colDef(\r\n            cell = function(value) {\r\n              if (col == \"Percentage of Missing Values\") {\r\n                if (!is.na(value) && value >= 25) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              } else {\r\n                if (is.na(value)) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\")\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            },\r\n            headerStyle = list(textAlign = \"center\"),\r\n            style = list(textAlign = \"center\")\r\n          )\r\n        }), columns)\r\n        \r\n        reactable(step_2_filtered, defaultPageSize = 10, columns = column_defs)\r\n        \r\n      }\r\n      \r\n      else if (input$dataViewSelect == \"Straightlined 15 Responses\") {\r\n        process_individual_examples(df, \"Straightlined 15 Responses\")\r\n        columns <- colnames(step_3_values) # Get the column names of the data\r\n        \r\n        # Create a named list of column definitions with specific styling for \"Straightline Length\" column\r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          if (col == \"Straightline Length\") {\r\n            colDef(\r\n              cell = function(value) {\r\n                if (!is.na(value) && value >= 15) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            )\r\n          } else {\r\n            colDef(\r\n              headerStyle = list(textAlign = \"center\"),\r\n              style = list(textAlign = \"center\")\r\n            )\r\n          }\r\n        }), columns)\r\n        \r\n        reactable(step_3_values, defaultPageSize = 10, columns = column_defs)\r\n      }\r\n      \r\n      else if (input$dataViewSelect == \"Repeated Straightline Behavior\") {\r\n        process_individual_examples(df, \"Repeated Straightline Behavior\")\r\n        columns <- colnames(step_4_values) # Get the column names of the data\r\n        \r\n        # Create a named list of column definitions with specific styling for the specified columns\r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          if (col %in% c(\"# of Times Straightlined 7 or More Responses\", \"# of Subscales Straightlined\")) {\r\n            colDef(\r\n              cell = function(value) {\r\n                if (!is.na(value) && value >= 3) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            )\r\n          } else {\r\n            colDef(\r\n              headerStyle = list(textAlign = \"center\"),\r\n              style = list(textAlign = \"center\")\r\n            )\r\n          }\r\n        }), columns)\r\n        \r\n        reactable(step_4_values, defaultPageSize = 10, columns = column_defs)\r\n      }\r\n      \r\n      else if (input$dataViewSelect == \"Other Repetitive Behavior\") {\r\n        process_individual_examples(df, \"Other Repetitive Behavior\")\r\n        columns <- colnames(step_6_values) # Get the column names of the data\r\n        \r\n        # Create a named list of column definitions with specific styling for the specified columns\r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          if (col %in% c(\"Flagged for Repetitive Behavior\")) {\r\n            colDef(\r\n              cell = function(value) {\r\n                if (!is.na(value) && value == 1) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            )\r\n          } else {\r\n            colDef(\r\n              headerStyle = list(textAlign = \"center\"),\r\n              style = list(textAlign = \"center\")\r\n            )\r\n          }\r\n        }), columns)\r\n        \r\n        reactable(step_6_values, defaultPageSize = 10, columns = column_defs)\r\n      }\r\n      \r\n      else if (input$dataViewSelect == \"Unrealistic Quantitative Responses\") {\r\n        process_individual_examples(df, \"Unrealistic Quantitative Responses\")\r\n        columns <- colnames(step_7_values) # Get the column names of the data\r\n        \r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          colDef(\r\n            headerStyle = list(textAlign = \"center\"),\r\n            style = list(textAlign = \"center\")\r\n          )\r\n        }), columns)\r\n        \r\n        reactable(step_7_values, defaultPageSize = 10, columns = column_defs)\r\n      }\r\n    })\r\n    \r\n    \r\n    # Allow download of processed data\r\n    output$downloadData <- downloadHandler(\r\n      filename = function() {\r\n        paste(\"nsse_survey_low_effort_responses_\", Sys.Date(), \".xlsx\", sep = \"\")\r\n      },\r\n      content = function(file) {\r\n        # Create a new workbook\r\n        new_wb <- createWorkbook()\r\n        \r\n        # Define styles\r\n        header_style <- createStyle(textDecoration = \"bold\", fontSize = 14)\r\n        text_style <- createStyle(fontSize = 12, wrapText = TRUE)\r\n        bullet_style <- createStyle(fontSize = 12, wrapText = TRUE, indent = 1)\r\n        \r\n        # Add \"About\" sheet with the specified text\r\n        addWorksheet(new_wb, \"About\")\r\n        \r\n        about_text <- c(\r\n          \"This Excel file has your data and results from the 'Detecting Low Effort Surveys' tool. It contains the following sheets:\",\r\n          \"\",\r\n          \"1. 'Your Summary': A table displaying the frequency (and percentage) of how often respondents exhibited behaviors indicating low-effort responding.\",\r\n          \"2. 'Your Data': Your data with new columns indicating which respondents should be removed from future analyses.\",\r\n          \"\",\r\n          \"If you have any questions, please contact Steve at stevensherrin@gmail.com with the title 'Detecting Low Effort Surveys'.\"\r\n        )\r\n        \r\n        # Write the \"About\" text to the first column\r\n        writeData(new_wb, \"About\", about_text, startCol = 1, startRow = 1)\r\n        \r\n        # Apply styles to the text\r\n        addStyle(new_wb, \"About\", header_style, rows = 1, cols = 1)\r\n        addStyle(new_wb, \"About\", text_style, rows = 2:2, cols = 1, gridExpand = TRUE)\r\n        addStyle(new_wb, \"About\", bullet_style, rows = 3:5, cols = 1, gridExpand = TRUE)\r\n        addStyle(new_wb, \"About\", text_style, rows = 6:6, cols = 1, gridExpand = TRUE)\r\n        \r\n        # Adjust column width to fit content\r\n        setColWidths(new_wb, \"About\", cols = 1, widths = 100)\r\n        \r\n        # Add the summary sheet with data\r\n        addWorksheet(new_wb, \"Your Summary\")\r\n        writeData(new_wb, \"Your Summary\", data())\r\n        \r\n        # Autofit the column widths for the \"Your Summary\" sheet\r\n        for (col in 1:ncol(data())) {\r\n          setColWidths(new_wb, \"Your Summary\", cols = col, widths = \"auto\")\r\n        }\r\n        \r\n        # Bold the top row of \"Your Summary\"\r\n        addStyle(new_wb, \"Your Summary\", header_style, rows = 1, cols = 1:ncol(data()), gridExpand = TRUE)\r\n        \r\n        # Style the last row of \"Your Summary\" with black fill and white font\r\n        last_row <- nrow(data()) + 1\r\n        last_row_style <- createStyle(fgFill = \"black\", fontColour = \"white\")\r\n        addStyle(new_wb, \"Your Summary\", last_row_style, rows = last_row, cols = 1:ncol(data()), gridExpand = TRUE)\r\n        \r\n        # Add a data sheet with detailed data\r\n        addWorksheet(new_wb, \"Your Data\")\r\n        \r\n        df2 <- df\r\n        df2 <- df2 %>% rename(`Row # in Original Data` = unique_id)\r\n        writeData(new_wb, \"Your Data\", df2)\r\n        \r\n        # Autofit the column widths for the \"Your Data\" sheet\r\n        for (col in 1:ncol(df)) {\r\n          setColWidths(new_wb, \"Your Data\", cols = col, widths = \"auto\")\r\n        }\r\n        \r\n        # Bold the column names of \"Your Data\"\r\n        addStyle(new_wb, \"Your Data\", header_style, rows = 1, cols = 1:ncol(df), gridExpand = TRUE)\r\n        \r\n        # Apply light blue background to the first two columns of \"Your Data\"\r\n        light_blue_style <- createStyle(fgFill = \"#ADD8E6\")\r\n        addStyle(new_wb, \"Your Data\", light_blue_style, rows = 1:nrow(df) + 1, cols = 1:2, gridExpand = TRUE)\r\n        \r\n        # Save the new workbook\r\n        saveWorkbook(new_wb, file, overwrite = TRUE)\r\n      }\r\n    )\r\n    \r\n    \r\n  })\r\n}\r\n\r\n# Run the application \r\nshinyApp(ui = ui, server = server)\r\n","type":"text"},{"name":"LICENSE","content":"GNU GENERAL PUBLIC LICENSE\r\n                       Version 2, June 1991\r\n\r\n Copyright (C) 1989, 1991 Free Software Foundation, Inc.,\r\n 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\r\n Everyone is permitted to copy and distribute verbatim copies\r\n of this license document, but changing it is not allowed.\r\n\r\n                            Preamble\r\n\r\n  The licenses for most software are designed to take away your\r\nfreedom to share and change it.  By contrast, the GNU General Public\r\nLicense is intended to guarantee your freedom to share and change free\r\nsoftware--to make sure the software is free for all its users.  This\r\nGeneral Public License applies to most of the Free Software\r\nFoundation's software and to any other program whose authors commit to\r\nusing it.  (Some other Free Software Foundation software is covered by\r\nthe GNU Lesser General Public License instead.)  You can apply it to\r\nyour programs, too.\r\n\r\n  When we speak of free software, we are referring to freedom, not\r\nprice.  Our General Public Licenses are designed to make sure that you\r\nhave the freedom to distribute copies of free software (and charge for\r\nthis service if you wish), that you receive source code or can get it\r\nif you want it, that you can change the software or use pieces of it\r\nin new free programs; and that you know you can do these things.\r\n\r\n  To protect your rights, we need to make restrictions that forbid\r\nanyone to deny you these rights or to ask you to surrender the rights.\r\nThese restrictions translate to certain responsibilities for you if you\r\ndistribute copies of the software, or if you modify it.\r\n\r\n  For example, if you distribute copies of such a program, whether\r\ngratis or for a fee, you must give the recipients all the rights that\r\nyou have.  You must make sure that they, too, receive or can get the\r\nsource code.  And you must show them these terms so they know their\r\nrights.\r\n\r\n  We protect your rights with two steps: (1) copyright the software, and\r\n(2) offer you this license which gives you legal permission to copy,\r\ndistribute and/or modify the software.\r\n\r\n  Also, for each author's protection and ours, we want to make certain\r\nthat everyone understands that there is no warranty for this free\r\nsoftware.  If the software is modified by someone else and passed on, we\r\nwant its recipients to know that what they have is not the original, so\r\nthat any problems introduced by others will not reflect on the original\r\nauthors' reputations.\r\n\r\n  Finally, any free program is threatened constantly by software\r\npatents.  We wish to avoid the danger that redistributors of a free\r\nprogram will individually obtain patent licenses, in effect making the\r\nprogram proprietary.  To prevent this, we have made it clear that any\r\npatent must be licensed for everyone's free use or not licensed at all.\r\n\r\n  The precise terms and conditions for copying, distribution and\r\nmodification follow.\r\n\r\n                    GNU GENERAL PUBLIC LICENSE\r\n   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\r\n\r\n  0. This License applies to any program or other work which contains\r\na notice placed by the copyright holder saying it may be distributed\r\nunder the terms of this General Public License.  The \"Program\", below,\r\nrefers to any such program or work, and a \"work based on the Program\"\r\nmeans either the Program or any derivative work under copyright law:\r\nthat is to say, a work containing the Program or a portion of it,\r\neither verbatim or with modifications and/or translated into another\r\nlanguage.  (Hereinafter, translation is included without limitation in\r\nthe term \"modification\".)  Each licensee is addressed as \"you\".\r\n\r\nActivities other than copying, distribution and modification are not\r\ncovered by this License; they are outside its scope.  The act of\r\nrunning the Program is not restricted, and the output from the Program\r\nis covered only if its contents constitute a work based on the\r\nProgram (independent of having been made by running the Program).\r\nWhether that is true depends on what the Program does.\r\n\r\n  1. You may copy and distribute verbatim copies of the Program's\r\nsource code as you receive it, in any medium, provided that you\r\nconspicuously and appropriately publish on each copy an appropriate\r\ncopyright notice and disclaimer of warranty; keep intact all the\r\nnotices that refer to this License and to the absence of any warranty;\r\nand give any other recipients of the Program a copy of this License\r\nalong with the Program.\r\n\r\nYou may charge a fee for the physical act of transferring a copy, and\r\nyou may at your option offer warranty protection in exchange for a fee.\r\n\r\n  2. You may modify your copy or copies of the Program or any portion\r\nof it, thus forming a work based on the Program, and copy and\r\ndistribute such modifications or work under the terms of Section 1\r\nabove, provided that you also meet all of these conditions:\r\n\r\n    a) You must cause the modified files to carry prominent notices\r\n    stating that you changed the files and the date of any change.\r\n\r\n    b) You must cause any work that you distribute or publish, that in\r\n    whole or in part contains or is derived from the Program or any\r\n    part thereof, to be licensed as a whole at no charge to all third\r\n    parties under the terms of this License.\r\n\r\n    c) If the modified program normally reads commands interactively\r\n    when run, you must cause it, when started running for such\r\n    interactive use in the most ordinary way, to print or display an\r\n    announcement including an appropriate copyright notice and a\r\n    notice that there is no warranty (or else, saying that you provide\r\n    a warranty) and that users may redistribute the program under\r\n    these conditions, and telling the user how to view a copy of this\r\n    License.  (Exception: if the Program itself is interactive but\r\n    does not normally print such an announcement, your work based on\r\n    the Program is not required to print an announcement.)\r\n\r\nThese requirements apply to the modified work as a whole.  If\r\nidentifiable sections of that work are not derived from the Program,\r\nand can be reasonably considered independent and separate works in\r\nthemselves, then this License, and its terms, do not apply to those\r\nsections when you distribute them as separate works.  But when you\r\ndistribute the same sections as part of a whole which is a work based\r\non the Program, the distribution of the whole must be on the terms of\r\nthis License, whose permissions for other licensees extend to the\r\nentire whole, and thus to each and every part regardless of who wrote it.\r\n\r\nThus, it is not the intent of this section to claim rights or contest\r\nyour rights to work written entirely by you; rather, the intent is to\r\nexercise the right to control the distribution of derivative or\r\ncollective works based on the Program.\r\n\r\nIn addition, mere aggregation of another work not based on the Program\r\nwith the Program (or with a work based on the Program) on a volume of\r\na storage or distribution medium does not bring the other work under\r\nthe scope of this License.\r\n\r\n  3. You may copy and distribute the Program (or a work based on it,\r\nunder Section 2) in object code or executable form under the terms of\r\nSections 1 and 2 above provided that you also do one of the following:\r\n\r\n    a) Accompany it with the complete corresponding machine-readable\r\n    source code, which must be distributed under the terms of Sections\r\n    1 and 2 above on a medium customarily used for software interchange; or,\r\n\r\n    b) Accompany it with a written offer, valid for at least three\r\n    years, to give any third party, for a charge no more than your\r\n    cost of physically performing source distribution, a complete\r\n    machine-readable copy of the corresponding source code, to be\r\n    distributed under the terms of Sections 1 and 2 above on a medium\r\n    customarily used for software interchange; or,\r\n\r\n    c) Accompany it with the information you received as to the offer\r\n    to distribute corresponding source code.  (This alternative is\r\n    allowed only for noncommercial distribution and only if you\r\n    received the program in object code or executable form with such\r\n    an offer, in accord with Subsection b above.)\r\n\r\nThe source code for a work means the preferred form of the work for\r\nmaking modifications to it.  For an executable work, complete source\r\ncode means all the source code for all modules it contains, plus any\r\nassociated interface definition files, plus the scripts used to\r\ncontrol compilation and installation of the executable.  However, as a\r\nspecial exception, the source code distributed need not include\r\nanything that is normally distributed (in either source or binary\r\nform) with the major components (compiler, kernel, and so on) of the\r\noperating system on which the executable runs, unless that component\r\nitself accompanies the executable.\r\n\r\nIf distribution of executable or object code is made by offering\r\naccess to copy from a designated place, then offering equivalent\r\naccess to copy the source code from the same place counts as\r\ndistribution of the source code, even though third parties are not\r\ncompelled to copy the source along with the object code.\r\n\r\n  4. You may not copy, modify, sublicense, or distribute the Program\r\nexcept as expressly provided under this License.  Any attempt\r\notherwise to copy, modify, sublicense or distribute the Program is\r\nvoid, and will automatically terminate your rights under this License.\r\nHowever, parties who have received copies, or rights, from you under\r\nthis License will not have their licenses terminated so long as such\r\nparties remain in full compliance.\r\n\r\n  5. You are not required to accept this License, since you have not\r\nsigned it.  However, nothing else grants you permission to modify or\r\ndistribute the Program or its derivative works.  These actions are\r\nprohibited by law if you do not accept this License.  Therefore, by\r\nmodifying or distributing the Program (or any work based on the\r\nProgram), you indicate your acceptance of this License to do so, and\r\nall its terms and conditions for copying, distributing or modifying\r\nthe Program or works based on it.\r\n\r\n  6. Each time you redistribute the Program (or any work based on the\r\nProgram), the recipient automatically receives a license from the\r\noriginal licensor to copy, distribute or modify the Program subject to\r\nthese terms and conditions.  You may not impose any further\r\nrestrictions on the recipients' exercise of the rights granted herein.\r\nYou are not responsible for enforcing compliance by third parties to\r\nthis License.\r\n\r\n  7. If, as a consequence of a court judgment or allegation of patent\r\ninfringement or for any other reason (not limited to patent issues),\r\nconditions are imposed on you (whether by court order, agreement or\r\notherwise) that contradict the conditions of this License, they do not\r\nexcuse you from the conditions of this License.  If you cannot\r\ndistribute so as to satisfy simultaneously your obligations under this\r\nLicense and any other pertinent obligations, then as a consequence you\r\nmay not distribute the Program at all.  For example, if a patent\r\nlicense would not permit royalty-free redistribution of the Program by\r\nall those who receive copies directly or indirectly through you, then\r\nthe only way you could satisfy both it and this License would be to\r\nrefrain entirely from distribution of the Program.\r\n\r\nIf any portion of this section is held invalid or unenforceable under\r\nany particular circumstance, the balance of the section is intended to\r\napply and the section as a whole is intended to apply in other\r\ncircumstances.\r\n\r\nIt is not the purpose of this section to induce you to infringe any\r\npatents or other property right claims or to contest validity of any\r\nsuch claims; this section has the sole purpose of protecting the\r\nintegrity of the free software distribution system, which is\r\nimplemented by public license practices.  Many people have made\r\ngenerous contributions to the wide range of software distributed\r\nthrough that system in reliance on consistent application of that\r\nsystem; it is up to the author/donor to decide if he or she is willing\r\nto distribute software through any other system and a licensee cannot\r\nimpose that choice.\r\n\r\nThis section is intended to make thoroughly clear what is believed to\r\nbe a consequence of the rest of this License.\r\n\r\n  8. If the distribution and/or use of the Program is restricted in\r\ncertain countries either by patents or by copyrighted interfaces, the\r\noriginal copyright holder who places the Program under this License\r\nmay add an explicit geographical distribution limitation excluding\r\nthose countries, so that distribution is permitted only in or among\r\ncountries not thus excluded.  In such case, this License incorporates\r\nthe limitation as if written in the body of this License.\r\n\r\n  9. The Free Software Foundation may publish revised and/or new versions\r\nof the General Public License from time to time.  Such new versions will\r\nbe similar in spirit to the present version, but may differ in detail to\r\naddress new problems or concerns.\r\n\r\nEach version is given a distinguishing version number.  If the Program\r\nspecifies a version number of this License which applies to it and \"any\r\nlater version\", you have the option of following the terms and conditions\r\neither of that version or of any later version published by the Free\r\nSoftware Foundation.  If the Program does not specify a version number of\r\nthis License, you may choose any version ever published by the Free Software\r\nFoundation.\r\n\r\n  10. If you wish to incorporate parts of the Program into other free\r\nprograms whose distribution conditions are different, write to the author\r\nto ask for permission.  For software which is copyrighted by the Free\r\nSoftware Foundation, write to the Free Software Foundation; we sometimes\r\nmake exceptions for this.  Our decision will be guided by the two goals\r\nof preserving the free status of all derivatives of our free software and\r\nof promoting the sharing and reuse of software generally.\r\n\r\n                            NO WARRANTY\r\n\r\n  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY\r\nFOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN\r\nOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES\r\nPROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED\r\nOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF\r\nMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS\r\nTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE\r\nPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,\r\nREPAIR OR CORRECTION.\r\n\r\n  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING\r\nWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR\r\nREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,\r\nINCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING\r\nOUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED\r\nTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY\r\nYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER\r\nPROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE\r\nPOSSIBILITY OF SUCH DAMAGES.\r\n\r\n                     END OF TERMS AND CONDITIONS\r\n\r\n            How to Apply These Terms to Your New Programs\r\n\r\n  If you develop a new program, and you want it to be of the greatest\r\npossible use to the public, the best way to achieve this is to make it\r\nfree software which everyone can redistribute and change under these terms.\r\n\r\n  To do so, attach the following notices to the program.  It is safest\r\nto attach them to the start of each source file to most effectively\r\nconvey the exclusion of warranty; and each file should have at least\r\nthe \"copyright\" line and a pointer to where the full notice is found.\r\n\r\n    <one line to give the program's name and a brief idea of what it does.>\r\n    Copyright (C) <year>  <name of author>\r\n\r\n    This program is free software; you can redistribute it and/or modify\r\n    it under the terms of the GNU General Public License as published by\r\n    the Free Software Foundation; either version 2 of the License, or\r\n    (at your option) any later version.\r\n\r\n    This program is distributed in the hope that it will be useful,\r\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n    GNU General Public License for more details.\r\n\r\n    You should have received a copy of the GNU General Public License along\r\n    with this program; if not, write to the Free Software Foundation, Inc.,\r\n    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.\r\n\r\nAlso add information on how to contact you by electronic and paper mail.\r\n\r\nIf the program is interactive, make it output a short notice like this\r\nwhen it starts in an interactive mode:\r\n\r\n    Gnomovision version 69, Copyright (C) year name of author\r\n    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.\r\n    This is free software, and you are welcome to redistribute it\r\n    under certain conditions; type `show c' for details.\r\n\r\nThe hypothetical commands `show w' and `show c' should show the appropriate\r\nparts of the General Public License.  Of course, the commands you use may\r\nbe called something other than `show w' and `show c'; they could even be\r\nmouse-clicks or menu items--whatever suits your program.\r\n\r\nYou should also get your employer (if you work as a programmer) or your\r\nschool, if any, to sign a \"copyright disclaimer\" for the program, if\r\nnecessary.  Here is a sample; alter the names:\r\n\r\n  Yoyodyne, Inc., hereby disclaims all copyright interest in the program\r\n  `Gnomovision' (which makes passes at compilers) written by James Hacker.\r\n\r\n  <signature of Ty Coon>, 1 April 1989\r\n  Ty Coon, President of Vice\r\n\r\nThis General Public License does not permit incorporating your program into\r\nproprietary programs.  If your program is a subroutine library, you may\r\nconsider it more useful to permit linking proprietary applications with the\r\nlibrary.  If this is what you want to do, use the GNU Lesser General\r\nPublic License instead of this License.\n","type":"text"},{"name":"README.md","content":"# Low-Effort-IR-Survey-Responses-App\n App for detecting low-effort responses for popular IR surveys\n","type":"text"},{"name":"deploy_shinylive.R","content":"library(shinylive)\r\nlibrary(fs)\r\n#sessionInfo()\r\n\r\n# Define the path to your existing Shiny app\r\nexisting_app_path <- \"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Documents/GitHub/Low-Effort-IR-Survey-Responses-App\"\r\n\r\nshinylive::export(appdir = existing_app_path, destdir = \"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Documents/GitHub/Low-Effort-IR-Survey-Responses-App/docs\")\r\n\r\n#httpuv::runStaticServer(\"docs\")\r\n\r\nhttpuv::runStaticServer(\"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Documents/GitHub/Low-Effort-IR-Survey-Responses-App/docs\")\r\n\r\n#httpuv::runStaticServer(\"docs/\", port=8008)\r\n\r\n\r\n","type":"text"},{"name":"helpers.R","content":"# Load necessary libraries\r\n#library(tidyverse)\r\nlibrary(openxlsx) #YES\r\nlibrary(writexl) #Yes\r\nlibrary(dplyr) #YES\r\nlibrary(tidyr) #YES\r\nlibrary(ggplot2) #YES\r\nlibrary(purrr) #YES\r\nlibrary(janitor) #YES\r\nlibrary(gtools) #YES\r\nlibrary(conflicted) #YES\r\nlibrary(reactable) #YES\r\nlibrary(scales) #YES\r\nlibrary(crosstalk) #YES\r\nlibrary(htmltools) #Yes\r\n\r\nconflicts_prefer(base::as.numeric())\r\nconflicts_prefer(base::is.character())\r\nconflicts_prefer(base::`&&`)\r\nconflicts_prefer(base::`||`)\r\nconflicts_prefer(dplyr::filter)\r\nconflicts_prefer(dplyr::lag)\r\n\r\ndone <- 0\r\n\r\n# List of required variables\r\nrequired_vars <- c(\r\n  \"askquest\", \"drafts\", \"unprepared\", \"attendart\",\r\n  \"CLaskhelp\", \"CLexplain\", \"CLstudy\", \"CLproject\", \"present\",\r\n  \"RIintegrate\", \"RIsocietal\", \"RIdiverse\", \"RIownview\", \"RIperspect\",\r\n  \"RInewview\", \"RIconnect\", \"SFcareer\", \"SFotherwork\", \"SFdiscuss\",\r\n  \"SFperform\", \"memorize\", \"HOapply\", \"HOanalyze\", \"HOevaluate\",\r\n  \"HOform\", \"ETgoals\", \"ETorganize\", \"ETexample\", \"ETdraftfb\",\r\n  \"ETfeedback\", \"QRconclude\", \"QRproblem\", \"QRevaluate\", \r\n  \"DDrace\", \"DDeconomic\", \"DDreligion\", \"DDpolitical\",\r\n  \"LSreading\", \"LSnotes\", \"LSsummary\",\r\n  \"challenge\", \"intern\", \"leader\", \"learncom\", \"abroad\",\r\n  \"research\", \"capstone\", \"servcourse\",\r\n  \"QIstudent\", \"QIadvisor\", \"QIfaculty\", \"QIstaff\", \"QIadmin\",\r\n  \"empstudy\", \"SEacademic\", \"SElearnsup\", \"SEdiverse\", \"SEsocial\", \"SEwellness\", \"SEnonacad\", \"SEactivities\", \"SEevents\",\r\n  \"pgwrite\", \"pgwspeak\",\"pgthink\", \"pganalyze\", \"pgwork\", \"pgothers\", \"pgvalues\", \"pgdiverse\", \"pgprobsolve\", \"pgcitizen\",\r\n  \"tmprephrs\",\"tmcocurrhrs\", \"tmworkonhrs\", \"tmworkoffhrs\", \"tmservicehrs\",\r\n  \"tmrelaxhrs\", \"tmcarehrs\", \"tmcommutehrs\", \"duration\"\r\n)\r\n\r\n# Function to check required variables\r\ncheck_missing_vars <- function(df) {\r\n  # Get the column names of the dataframe\r\n  df_columns <- colnames(df)\r\n  \r\n  # Check for the presence of specific required columns\r\n  missing_vars <- setdiff(required_vars, df_columns)\r\n  \r\n  # Print missing variables if any\r\n  if (length(missing_vars) > 0) {\r\n    print(paste(\"The following columns are missing from your raw NSSE file:\", \r\n                paste(missing_vars, collapse = \", \"), \r\n                \". Some of this may be due to analyzing a particular year from NSSE, especially older years. Keep in mind this may prevent the analysis from running properly.\"))\r\n  } else {\r\n    print(\"All required columns are present.\")\r\n  }\r\n  \r\n}\r\n\r\n# Function to remove recoded and estimated variables\r\n# (In some cases - such as hours per week questions - we do choose to keep the estimated variables and remove the original ones)\r\nremove_recoded_vars <- function(df) {\r\n  # Create list of possible variables to remove\r\n  # (This will depend on year of survey - not all variables will be present in all years)\r\n  recoded_vars <- c(\"unpreparedr\",\r\n                    \"wrshortnum\",\r\n                    \"wrmednum\",\r\n                    \"wrlongnum\",\r\n                    \"wrpages\",\r\n                    \"HIPsumFY\",\r\n                    \"HIPsumSR\",\r\n                    \"QIstudentR\",\r\n                    \"QIadvisorR\",\r\n                    \"QIfacultyR\",\r\n                    \"QIstaffR\",\r\n                    \"QIadminR\",\r\n                    \"tmprep\",\r\n                    \"tmcocurr\",\r\n                    \"tmworkon\",\r\n                    \"tmworkoff\",\r\n                    \"tmworkhrs\",\r\n                    \"tmservice\",\r\n                    \"tmrelax\",\r\n                    \"tmcare\",\r\n                    \"tmcommute\",\r\n                    \"tmread\",\r\n                    \"reading\",\r\n                    \"tmreadinghrscol\",\r\n                    \"wrshort\", # These \"wr\"/writing questions are wedged in the middle of the main page and have a different response scale. They are not used in the main analyses.\r\n                    \"wrmed\", # See above\r\n                    \"wrlong\",\r\n                    \"wrshortnum\",\r\n                    \"wrmednum\",\r\n                    \"wrlongnum\",\r\n                    \"wrpages\")\r\n  \r\n  # Remove recoded variables from the dataframe\r\n  df <- df %>%\r\n    select(-any_of(recoded_vars))\r\n  \r\n  print(\"Removed recoded and/or estimated variables not used in analyses.\")\r\n  \r\n  return(df)\r\n}\r\n\r\n# Function to read the uploaded file\r\nread_uploaded_file <- function(file) {\r\n  ext <- tools::file_ext(file$name)\r\n  if (ext == \"csv\") {\r\n    df <- read.csv(file$datapath)\r\n  } else if (ext == \"xlsx\") {\r\n    df <- read.xlsx(file$datapath)\r\n  } else {\r\n    stop(\"Invalid file type. Please upload a .csv or .xlsx file.\")\r\n  }\r\n  assign(\"df\", df, envir = .GlobalEnv)\r\n  return(df)\r\n}\r\n\r\n# Function to clean and prepare the dataframe\r\nclean_data <- function(df) {\r\n  # Clean column names\r\n  df <- clean_names(df)\r\n  print(\"Column names successfully cleaned\")\r\n  \r\n  # Check if all columns have valid names\r\n  na_or_empty_names <- which(is.na(names(df)) | names(df) == \"\")\r\n  \r\n  # Print columns that have invalid names; if there are none, say \"No columns with NA or empty names\"\r\n  if (length(na_or_empty_names) > 0) {\r\n    cat(\"Columns with NA or empty names:\", na_or_empty_names, \"\\n\")\r\n    # Assign new names to these columns, for example: V1, V2, etc.\r\n    names(df)[na_or_empty_names] <- paste(\"V\", na_or_empty_names, sep = \"\")\r\n  } else {\r\n    print(\"No columns with NA or empty names\")\r\n  }\r\n  \r\n  # Create a unique identifier for each row\r\n  df <- df %>%\r\n    mutate(unique_id = paste0(row_number()))\r\n  print(\"Unique identifier for each row created\")\r\n  \r\n  assign(\"df\", df, envir = .GlobalEnv)\r\n  return(df)\r\n}\r\n\r\n# Function to process the data for summary table\r\ncalculate_summary <- function(df) {\r\n  summary_df <- tibble(\r\n    Criteria = c(\"Responses in raw NSSE dataset\",\r\n                 \"Completed survey in 3 minutes or less\", \r\n                 \"Skipped over 25% of survey questions\",\r\n                 \"Straightlined 15 or more responses in a row\",\r\n                 \"Had 3 or more times they straightlined least 7 responses in a row\",\r\n                 \"Straightlined 3 or more scales\",\r\n                 \"Made repetitive pattern (e.g. AB-AB-AB) 50% or more of the time\",\r\n                 \"Unrealistic response to quantitative question (e.g. hours per week)\",\r\n                 \"Highly unusual responses to highly correlated items\"),\r\n    `Percentage of Total Respondents Removed` = c(\r\n      0,\r\n      abs(row_changes[1]) / nrow(df),\r\n      abs(row_changes[2]) / nrow(df),\r\n      abs(row_changes[3]) / nrow(df),\r\n      abs(row_changes[4]) / nrow(df),\r\n      abs(row_changes[5]) / nrow(df),\r\n      abs(row_changes[6]) / nrow(df),\r\n      abs(row_changes[7]) / nrow(df),\r\n      abs(row_changes[8]) / nrow(df)\r\n      \r\n    ),\r\n    `Total Respondents Excluded` = c(\r\n      0,\r\n      abs(row_changes[1]),\r\n      abs(row_changes[2]),\r\n      abs(row_changes[3]),\r\n      abs(row_changes[4]),\r\n      abs(row_changes[5]),\r\n      abs(row_changes[6]),\r\n      abs(row_changes[7]),\r\n      abs(row_changes[8])\r\n    ))\r\n    \r\n  summary_df <- summary_df %>%\r\n    mutate(`Total Remaining Respondents` = nrow(df) - cumsum(`Total Respondents Excluded`)) %>%\r\n    mutate(`Total Remaining Respondents` = replace(`Total Remaining Respondents`, 1, nrow(df)))\r\n  \r\n  summary_df <- summary_df %>%\r\n    select(Criteria, `Total Remaining Respondents`, everything())\r\n  \r\n  #Starting at row #2, add \"Filter/Step X: \" to the beginning of each Criteria. Start with step 1.\r\n  summary_df$Criteria[2:nrow(summary_df)] <- paste0(\"Filter/Step \", 1:(nrow(summary_df)-1), \": \", summary_df$Criteria[2:nrow(summary_df)])\r\n\r\n  #Create a summary row with the sums, except for \"Total Remaining Respondents\", which is the last found value for that column\r\n  summary_df <- summary_df %>%\r\n    bind_rows(\r\n      tibble(\r\n        Criteria = \"Final\",\r\n        `Percentage of Total Respondents Removed` = sum(summary_df$`Percentage of Total Respondents Removed`),\r\n        `Total Respondents Excluded` = sum(summary_df$`Total Respondents Excluded`),\r\n        `Total Remaining Respondents` = summary_df$`Total Remaining Respondents`[[nrow(summary_df)]]\r\n      )\r\n    )\r\n  \r\n  assign(\"summary_df\", summary_df, envir = .GlobalEnv)\r\n  return(summary_df)\r\n}\r\n\r\n# Function to generate DiagrammeR graph\r\n# generate_diagram <- function(summary_df) {\r\n  # summary_df <- summary_df %>%\r\n  #   mutate(label = paste0(Criteria, \"\\nExcluded: \", Excluded, \"\\nRemaining: \", Remaining))\r\n  # \r\n  # nodes <- paste0(\r\n  #   \"node [shape = box, style = filled, fillcolor = LightSkyBlue]\",\r\n  #   paste0(\"n\", 1:nrow(summary_df), \" [label = '\", summary_df$label, \"'];\", collapse = \"\\n\")\r\n  # )\r\n  # \r\n  # edges <- paste0(\r\n  #   paste0(\"n\", 1:(nrow(summary_df)-1), \" -> n\", 2:nrow(summary_df), \";\", collapse = \"\\n\")\r\n  # )\r\n  # \r\n  # graph <- paste0(\r\n  #   \"digraph flowchart {\",\r\n  #   nodes, \"\\n\",\r\n  #   edges, \"\\n\",\r\n  #   \"}\"\r\n  # )\r\n  # \r\n  # return(grViz(graph))\r\n  \r\n  # design <- tibble::tribble(\r\n  #   ~left,               ~n_left, ~right,              ~n_right,\r\n  #   \"Study base\",        1000,    \"Not sampled\",       250,\r\n  #   \"Study population\",  750,     \"Participants with\\nmissing exposure data\", 100,\r\n  #   \"Complete-case set\", 650,     \"\",                  NA_integer_)\r\n  # \r\n  # # Plot\r\n  # exclusion_flowchart(design, width = 2)\r\n# }\r\n\r\n\r\n# Format summary table\r\nformat_percentage_cell <- function(value) {\r\n  # Ensure value is between 0 and 1 for percentages\r\n  value <- min(max(value, 0), 1)\r\n  # Rescale value to 0-1 range for gradient\r\n  gradientValue <- scales::rescale(value, c(0, 1), c(0, 1))\r\n  # Use the gradient value to interpolate between white and red\r\n  color <- colorRampPalette(c(\"white\", \"red\"))(100)[as.integer(gradientValue * 99) + 1]\r\n  style <- paste(\"background-color:\", color, \"; color: black;\") # Set font color to black\r\n  htmltools::span(style = style, scales::percent(value, accuracy = 0.1))\r\n}\r\n\r\n# Function to process individual examples based on selected view\r\nprocess_individual_examples <- function(df, view_select) {\r\n  if (view_select == \"Completed survey in 3 minutes or less\") {\r\n\r\n    step_1_filtered <- df %>%\r\n      select(unique_id, duration) %>%\r\n      mutate(duration = round(as.numeric(duration), 1)) %>%\r\n      arrange(duration)\r\n    \r\n    step_1_filtered <- step_1_filtered %>%\r\n      rename(\r\n        `Row in Dataset` = unique_id,\r\n        `Duration (minutes)` = duration\r\n      )\r\n    \r\n    # Add to global environment\r\n    assign(\"step_1_filtered\", step_1_filtered, envir = .GlobalEnv)\r\n    \r\n    return(step_1_filtered)\r\n    \r\n  } else if (view_select == \"Skipped over 25% of survey questions\") {\r\n    \r\n    step_2_filtered <- step_1 %>%\r\n      mutate(missing_percentage = round(rowSums(is.na(.)) / ncol(.) * 100),1)\r\n    \r\n    step_2_filtered <- step_2_filtered %>%\r\n      select(missing_percentage, unique_id, everything())\r\n    \r\n    step_2_filtered <- step_2_filtered %>%\r\n      arrange(desc(missing_percentage))\r\n    \r\n    step_2_filtered <- step_2_filtered %>%\r\n      rename(\r\n        `Row in Dataset` = unique_id,\r\n        `Percentage of Missing Values` = missing_percentage\r\n      )\r\n    \r\n\r\n    # Add to global environment\r\n    assign(\"step_2_filtered\", step_2_filtered, envir = .GlobalEnv)\r\n    \r\n    return(step_2_filtered)\r\n  }\r\n  \r\n  \r\n  else if (view_select == \"Straightlined 15 Responses\") {\r\n    \r\n    step_3_values <- step_3_values %>%\r\n      arrange(desc(longstring)) %>%\r\n      rename(`Row in Dataset` = unique_id,\r\n             `Straightline Length` = longstring)\r\n    \r\n    \r\n    # Add to global environment\r\n    assign(\"step_3_values\", step_3_values, envir = .GlobalEnv)\r\n    \r\n    return(step_3_values)\r\n  }\r\n  \r\n  else if (view_select == \"Repeated Straightline Behavior\") {\r\n    \r\n    step_4_values <- merge(step_4_values, step_5_values,\r\n                           by = \"unique_id\",\r\n                           all.x = TRUE)\r\n    \r\n    step_4_values <- step_4_values %>%\r\n      arrange(desc(longstring_7_or_more)) %>%\r\n      rename(`Row in Dataset` = unique_id,\r\n             `# of Times Straightlined 7 or More Responses` = longstring_7_or_more,\r\n             `# of Subscales Straightlined` = longstring_3_or_more_scales)\r\n    \r\n    step_4_values <- step_4_values %>%\r\n      select(`Row in Dataset`, \r\n             `# of Times Straightlined 7 or More Responses`, \r\n             `# of Subscales Straightlined`,\r\n             everything())\r\n    \r\n    step_4_values <- step_4_values %>% select(-longstring)\r\n    \r\n    # Add to global environment\r\n    assign(\"step_4_values\", step_4_values, envir = .GlobalEnv)\r\n    \r\n    return(step_4_values)\r\n  }\r\n  \r\n  else if (view_select == \"Other Repetitive Behavior\") {\r\n    step_6_values <- step_6_values %>%\r\n      arrange(desc(repetitive), desc(rp_2)) %>%\r\n      rename(`Row in Dataset` = unique_id,\r\n             `Flagged for Repetitive Behavior` = repetitive,\r\n             `% of Times Previous Response Repeated` = rp_2,\r\n             `% of Times 2nd Previous Response Repeated` = rp_3,\r\n             `% of Times 3rd Previous Response Repeated` = rp_4,\r\n             `% of Times 4th Previous Response Repeated` = rp_5) %>%\r\n      # Divide the variables with \"%\" in the name by 100 and then format as percentages\r\n      mutate(across(contains(\"%\"), ~ . / 100)) %>%\r\n      mutate(across(contains(\"%\"), ~ scales::percent(., accuracy = 0.1)))\r\n    \r\n    assign(\"step_6_values\", step_6_values, envir = .GlobalEnv)\r\n    \r\n    return(step_6_values)\r\n  }\r\n  \r\n  else if (view_select == \"Unrealistic Quantitative Responses\") {\r\n    step_7_values <- step_7_values %>%\r\n      arrange(desc(total_hours_per_week)) %>%\r\n      rename(`Row in Dataset` = unique_id,\r\n             `Total Hours per Week` = total_hours_per_week) %>%\r\n      mutate(`Flagged for Unrealistic Hours?` = ifelse( `Total Hours per Week` > 140, \"Yes\", \"No\")) %>%\r\n      mutate(`Total Hours per Week` = ifelse(is.na(`Total Hours per Week`), 0, `Total Hours per Week`)) %>%\r\n      select(`Row in Dataset`, `Total Hours per Week`, `Flagged for Unrealistic Hours?`, everything())\r\n    \r\n    assign(\"step_7_values\", step_7_values, envir = .GlobalEnv)\r\n    \r\n    return(step_7_values)\r\n  }\r\n  \r\n\r\n    \r\n}\r\n\r\n# Function to identify careless responses\r\nidentify_careless_responses <- function(df) {\r\n  \r\n  ############################################\r\n  ### Metrics for Main Page of NSSE Survey ###\r\n  ###########################################\r\n  \r\n  # Subsetting and transforming data for the first page of survey\r\n  df_main_page <- df %>%\r\n    select(unique_id, duration, askquest:s_eevents) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) # Convert all columns to numeric\r\n  \r\n  # Extracting unique IDs\r\n  first_page_ids <- df_main_page$unique_id\r\n  #df_main_page <- df_main_page %>% select(-unique_id)\r\n  \r\n  # Perform your specific analysis (placeholder for your functions)\r\n  # longstring, na measures, psychsyn, and mahad analysis\r\n  # Ensure these functions are defined or loaded from respective libraries\r\n  \r\n  #Step 1: Screen low duration\r\n  step_1 <- df_main_page %>%\r\n    filter(as.numeric(duration) > 3) %>%\r\n    select(-duration)\r\n  \r\n  print(\"Step 1 completed\")\r\n  \r\n  #Step 2: Screen for high number of missing values\r\n  step_2 <- step_1 %>%\r\n    filter(rowSums(is.na(step_1)) < 15)\r\n  \r\n  print(\"Step 2 completed\")\r\n  \r\n  #Step 3: Screen for longstrings of 15 or more\r\n  step_3 <- step_2 %>%\r\n    mutate(longstring = longstring(step_2)) \r\n  \r\n  step_3_values <- step_3 %>%\r\n    select(unique_id, longstring, everything())\r\n  \r\n  step_3 <- step_3 %>%\r\n    filter(longstring < 15)\r\n  \r\n  print(\"Step 3 completed\")\r\n  \r\n  #Step 4: Screen for repeated longstrings of more than 6\r\n  step_4 <- step_3 %>%\r\n    mutate(longstring_7_or_more = longstring_n_times(step_3, threshold = 6)$count_longstr) \r\n  \r\n  step_4_values <- step_4 %>%\r\n    select(unique_id, longstring_7_or_more, everything())\r\n  \r\n  step_4 <- step_4 %>%\r\n    filter(longstring_7_or_more < 3)\r\n  \r\n  print(\"Step 4 completed\")\r\n  \r\n  #Step 5: Screen for respondents who answer 3 or more scales with 0 variance\r\n  #Calculate longstrings for each question set (\"q_set_\") and return the number \"1\" if the longstring equals the number of responses\r\n  # Define question sets\r\n  question_sets <- list(\r\n    q_set_1 = c(\"askquest\", \"c_laskhelp\", \"c_lexplain\", \"c_lstudy\", \"c_lproject\", \"present\"),\r\n    q_set_2 = c(\"r_iintegrate\", \"r_isocietal\", \"r_idiverse\", \"r_iownview\", \"r_iperspect\", \"r_inewview\", \"r_iconnect\"),\r\n    q_set_3 = c(\"memorize\", \"h_oapply\", \"h_oanalyze\", \"h_oevaluate\", \"h_oform\"),\r\n    q_set_4 = c(\"e_tgoals\", \"e_torganize\", \"e_texample\", \"e_tdraftfb\", \"e_tfeedback\", \"e_tcriteria\", \"e_treview\", \"e_tprefer\", \"e_tdemonstrate\"),\r\n    q_set_5 = c(\"d_drace\", \"d_deconomic\", \"d_dreligion\", \"d_dpolitical\", \"d_dsexorient\", \"d_dcountry\"),\r\n    q_set_6 = c(\"intern\", \"leader\", \"learncom\", \"abroad\", \"research\", \"capstone\", \"servcourse\"),\r\n    q_set_7 = c(\"empstudy\", \"s_eacademic\", \"s_elearnsup\", \"s_ediverse\", \"s_esocial\", \"s_ewellness\", \"s_enonacad\", \"s_eactivities\", \"s_eevents\"),\r\n    q_set_8 = c(\"tmprephrs\", \"tmcocurrhrs\", \"tmworkonhrs\", \"tmworkoffhrs\", \"tmservicehrs\", \"tmrelaxhrs\", \"tmcarehrs\", \"tmcommutehrs\")\r\n  )\r\n  \r\n  # Add variables from question sets to dataframe (if not already present)\r\n  vars_in_question_sets <- unique(unlist(question_sets))\r\n  \r\n  # Convert unique_id in step_4 and df to character\r\n  step_4$unique_id <- as.character(step_4$unique_id)\r\n  df$unique_id <- as.character(df$unique_id)\r\n  \r\n  step_5 <- step_4 %>%\r\n    left_join(df %>% select(unique_id, any_of(vars_in_question_sets)), by = \"unique_id\", suffix = c(\"\", \".df\")) %>%\r\n    select(-ends_with(\".df\"))\r\n  \r\n  # Function to calculate longstring ratio for a question set\r\n  calculate_longstring_ratio <- function(df, set_name, set_columns) {\r\n    df %>%\r\n      mutate(!!paste0(set_name, \"_longstring\") := as.numeric(longstring(select(., one_of(set_columns)))) / \r\n               rowSums(!is.na(select(., one_of(set_columns)))))\r\n  }\r\n  \r\n  # Iterate over all question sets and calculate longstring ratio\r\n  for (i in 1:length(question_sets)) {\r\n    set_name <- paste0(\"q_set_\", i)\r\n    set_columns <- question_sets[[set_name]]\r\n    step_5 <- calculate_longstring_ratio(step_5, set_name, set_columns)\r\n  }\r\n  \r\n  # Calculate the number of question sets with longstring ratio equal to 1\r\n  step_5 <- step_5 %>%\r\n    mutate(longstring_3_or_more_scales = rowSums(select(., starts_with(\"q_set_\")) == 1)) \r\n  \r\n  step_5_values <- step_5 %>%\r\n    select(unique_id, longstring_3_or_more_scales)\r\n  \r\n  step_5 <- step_5 %>%\r\n    filter(longstring_3_or_more_scales < 3)\r\n  \r\n  print(\"Step 5 completed\")\r\n\r\n  \r\n  #Step 6: Screen for 2-value repetitive pattern (e.g. AB-AB-AB)\r\n  # Keep only the columns found in df_main_page. (We'll add the other ones back later.)\r\n  #common_columns <- intersect(names(step_5), names(df_main_page))\r\n  \r\n  # step_6 <- step_5 %>%\r\n  #   select(all_of(common_columns), -unique_id)\r\n  \r\n  step_6 <- df %>%\r\n    select(unique_id, askquest:s_eevents) %>%\r\n    #keep only unique_ids found in step_5\r\n    filter(unique_id %in% step_5$unique_id) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) # Convert all columns to numeric\r\n\r\n  # Function to calculate percentage of repeated patterns\r\n  calculate_repeated_pattern_percentage <- function(data, lag) {\r\n    same_count <- rowSums(data == lag(data, n = lag, default = NA), na.rm = TRUE)\r\n    total_count <- rowSums(!is.na(data))\r\n    percentage <- (same_count / total_count) * 100\r\n    return(percentage)\r\n  }\r\n  \r\n  # Calculate percentages for different lags and store in new columns\r\n  step_6 <- step_6 %>%\r\n    mutate(rp_2 = calculate_repeated_pattern_percentage(across(everything()), 2),\r\n           rp_3 = calculate_repeated_pattern_percentage(across(everything()), 3),\r\n           rp_4 = calculate_repeated_pattern_percentage(across(everything()), 4),\r\n           rp_5 = calculate_repeated_pattern_percentage(across(everything()), 5))\r\n  \r\n  # If any of rp_2 to rp_5 is 50% or higher, flag the respondent\r\n  step_6 <- step_6 %>%\r\n    mutate(repetitive = ifelse(rowSums(select(., starts_with(\"rp_\")) >= 60) > 0, 1, 0))\r\n  \r\n  # Save step_6 before filtering\r\n  step_6_values <- step_6 %>%\r\n    select(unique_id, repetitive, contains(\"rp_\"), everything())\r\n  \r\n  # z <- step_6_values %>%\r\n  #   filter(repetitive == 1)\r\n  \r\n  # # Function to plot responses for a single respondent\r\n  # plot_responses <- function(responses, respondent_id, start_question, end_question) {\r\n  #   responses_subset <- responses[start_question:end_question]\r\n  #   responses_long <- data.frame(Question = names(responses_subset), Response = unlist(responses_subset))\r\n  #   responses_long <- responses_long[complete.cases(responses_long), ]\r\n  #   \r\n  #   ggplot(responses_long, aes(x = Response, y = factor(Question, levels = rev(names(responses_subset))))) +\r\n  #     geom_point(color = \"blue\", size = 3) +\r\n  #     geom_line(aes(group = 1), color = \"blue\") +\r\n  #     scale_x_continuous(breaks = 1:5, limits = c(1, 5)) +\r\n  #     theme(axis.text.y = element_text(angle = 0, hjust = 1)) +\r\n  #     ggtitle(paste(\"Responses for Respondent\", respondent_id, \"(Questions\", start_question, \"to\", end_question, \")\")) +\r\n  #     xlab(\"Response Option\") +\r\n  #     ylab(\"Questions\") +\r\n  #     theme_minimal()\r\n  # }\r\n  # \r\n  # # Loop through the respondents to generate the plots, 25 questions per page\r\n  # questions_per_page <- 25\r\n  # total_questions <- ncol(z)\r\n  # \r\n  # for (respondent_id in 1:nrow(z)) {\r\n  #   num_pages <- ceiling(total_questions / questions_per_page)\r\n  #   for (page in 1:num_pages) {\r\n  #     start_question <- (page - 1) * questions_per_page + 1\r\n  #     end_question <- min(page * questions_per_page, total_questions)\r\n  #     pdf(paste0(\"respondent_\", respondent_id, \"_page_\", page, \".pdf\"))\r\n  #     print(plot_responses(z[respondent_id, , drop = FALSE], respondent_id, start_question, end_question))\r\n  #     dev.off()\r\n  #   }\r\n  # }\r\n  \r\n  # Filter out respondents with repetitive patterns\r\n  step_6 <- step_6 %>%\r\n    filter(repetitive == 0 | is.na(repetitive) == TRUE)\r\n  \r\n  print(\"Step 6 completed\")\r\n  \r\n  # step_6_filtered <- step_6[, !grepl(\"^rp_\", colnames(step_6))]\r\n  # step_6_filtered <- step_6 %>% select(-unique_id)\r\n  # rep_pattern_algo = rp.patterns(step_6_filtered)\r\n  # indices <- rp.indices(rep_pattern_algo, include.coefs = FALSE)\r\n  # \r\n  # rp.plot(rep_pattern_algo, obs = 105)\r\n  \r\n  # Step 7: Screen for invalid responses to \"hours\" question set\r\n  # Create dataframe \"df_hours\" with variables found in list question_sets q_set_8\r\n  df_hours <- df %>%\r\n    select(unique_id, tmprephrs:tmcommutehrs) %>%\r\n    filter(unique_id %in% step_6$unique_id) %>%\r\n    #select(-unique_id) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) # Convert all columns to numeric\r\n  \r\n  # Calculate total hours per week\r\n  df_hours$total_hours_per_week <- rowSums(select(df_hours, -unique_id), na.rm = TRUE)\r\n  \r\n  # Add df_hours$total_hours_per_week to step_7 based on unique_id\r\n  step_7 <- step_6 %>%\r\n    left_join(df_hours, by = \"unique_id\")\r\n  \r\n  # Save results\r\n  step_7_values <- step_7 %>%\r\n    select(unique_id, total_hours_per_week, contains(\"tm\"))\r\n  \r\n  # Filter out respondents with unrealistic total hours per week\r\n  step_7 <- step_7 %>%\r\n    mutate(total_hours_per_week = ifelse(is.na(total_hours_per_week), 0, total_hours_per_week)) %>%\r\n    filter(total_hours_per_week <= 140)\r\n  \r\n  print(\"Step 7 completed\")\r\n\r\n  # Step 8: Screen for unusual responses to highly correlated items\r\n  step_8 <- df %>%\r\n    select(unique_id, askquest:sameinst) %>%\r\n    #keep only unique_ids found in step_6\r\n    filter(unique_id %in% step_7$unique_id) %>%\r\n    #convert all columns to numeric\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) %>%\r\n    #Remove any columns with all NAs\r\n    select(where(~!all(is.na(.))))\r\n  \r\n  step_8_filtered <- step_8 %>%\r\n    select(-unique_id) #-tmworkhrs)\r\n  \r\n  #Scale all variables in step_7_filtered\r\n  step_8_filtered <- step_8_filtered %>%\r\n    mutate(across(everything(), scale))\r\n  \r\n  step_8$mv_syn <- psychsyn(step_8_filtered, critval = .50)\r\n  step_8$mv_mahad <- scale(mahad(step_8_filtered))\r\n  \r\n  #Remove any rows with Mahalanobis distance greater than 3 and synonym correlation below 0\r\n  step_8 <- step_8 %>%\r\n    filter(mv_mahad < 3 & mv_syn > 0)\r\n  \r\n  print(\"Step 8 completed\")\r\n  \r\n  #Compare the number of rows in each step\r\n  steps <- list(df, step_1, step_2, step_3, step_4, step_5, step_6, step_7, step_8)\r\n  \r\n  # Initialize an empty vector to store the changes\r\n  row_changes <- vector(\"numeric\", length = length(steps) - 1)\r\n  \r\n  # Loop through the dataframes to calculate the changes in number of rows\r\n  for (i in 1:(length(steps) - 1)) {\r\n    row_changes[i] <- nrow(steps[[i + 1]]) - nrow(steps[[i]])\r\n  }\r\n\r\n  assign(\"row_changes\", row_changes, envir = .GlobalEnv)\r\n  \r\n  # Find last step each respondent was included in\r\n  # Initialize a data frame to store the results\r\n  last_occurrence <- data.frame(unique_id = unique(df$unique_id), last_dataframe = NA)\r\n  \r\n  # Loop over each unique_id in df\r\n  for (i in seq_along(last_occurrence$unique_id)) {\r\n    unique_id <- last_occurrence$unique_id[i]\r\n    # Loop over each dataframe in reverse order\r\n    for (j in length(steps):1) {\r\n      if (unique_id %in% steps[[j]]$unique_id) {\r\n        last_occurrence$last_dataframe[i] <- paste(\"step\", j-1, sep = \"_\")\r\n        break\r\n      }\r\n    }\r\n  }\r\n  \r\n  # Recode the last_dataframe column\r\n  last_occurrence <- last_occurrence %>%\r\n    mutate(last_dataframe = recode(last_dataframe, \r\n                                   `step_0` = \"Completed survey in 3 minutes or less\",\r\n                                   `step_1` = \"Skipped over 25% of survey questions\",\r\n                                   `step_2` = \"Straightlined 15 or more responses in a row\",\r\n                                   `step_3` = \"Had 3 or more times they straightlined least 7 responses in a row\",\r\n                                   `step_4` = \"Straightlined 3 or more scales\",\r\n                                   `step_5` = \"Made repetitive pattern (e.g. AB-AB-AB, ABC-ABC-ABC) 50% or more of the time\",\r\n                                   `step_6` = \"Unrealistic responses to quantitative question set (e.g. hours per week)\",\r\n                                   `step_7` = \"Highly unusual responses to highly correlated items\",\r\n                                   `step_8` = \"\")) %>%\r\n    rename(`Reason for Flag` = last_dataframe)\r\n  \r\n  # Add \"flagged\" column to last_occurrence\r\n  last_occurrence$`Flagged for Low Effort?` <- ifelse(last_occurrence$`Reason for Flag` == \"\", \"No\", \"Yes\")\r\n  \r\n  #Reorder columns\r\n  last_occurrence <- last_occurrence %>%\r\n    select(unique_id, `Flagged for Low Effort?`, `Reason for Flag`)\r\n  \r\n  #Add to df based on unique_id and move it to front\r\n  df <- df %>%\r\n    left_join(last_occurrence, by = \"unique_id\") %>%\r\n    select(`Flagged for Low Effort?`, `Reason for Flag`, unique_id, everything())\r\n\r\n  assign(\"df\", df, envir = .GlobalEnv)\r\n  assign(\"step_1\", step_1, envir = .GlobalEnv)\r\n  assign(\"step_2\", step_2, envir = .GlobalEnv)\r\n  assign(\"step_3\", step_3, envir = .GlobalEnv)\r\n  assign(\"step_4\", step_4, envir = .GlobalEnv)\r\n  assign(\"step_5\", step_5, envir = .GlobalEnv)\r\n  assign(\"step_6\", step_6, envir = .GlobalEnv)\r\n  assign(\"step_7\", step_7, envir = .GlobalEnv)\r\n  assign(\"step_8\", step_8, envir = .GlobalEnv)\r\n  \r\n  \r\n  assign(\"step_3_values\", step_3_values, envir = .GlobalEnv)\r\n  assign(\"step_4_values\", step_4_values, envir = .GlobalEnv)\r\n  assign(\"step_5_values\", step_5_values, envir = .GlobalEnv)\r\n  assign(\"step_6_values\", step_6_values, envir = .GlobalEnv)\r\n  assign(\"step_7_values\", step_7_values, envir = .GlobalEnv)\r\n  #assign(\"z\", z, envir = .GlobalEnv)\r\n  \r\n  return(df)\r\n}\r\n\r\n","type":"text"},{"name":"library_functions.R","content":"# Mahad function (from careless package)\r\nmahad <- function(x, plot = TRUE, flag = FALSE, confidence = 0.99, na.rm = TRUE) {\r\n  if(na.rm == FALSE) {\r\n    if(any(is.na(x)) == TRUE) {stop(\"Some values are NA. Mahalanobis distance was not computed.\r\n                                      Use na.rm = TRUE to use available cases.\", call. = FALSE)}\r\n  }\r\n  \r\n  #Subfunction \"mahad\" (from psych package)\r\n  outlier <- \r\n    function(x,plot=TRUE,bad=5,na.rm=TRUE,xlab,ylab,...) {\r\n      if(missing(xlab)) xlab <- expression(\"Quantiles of \" * ~chi ^2)\r\n      if(missing(ylab)) ylab <- expression(\"Mahalanobis \" * D^2)\r\n      rn <- rownames(x)\r\n      nvar <- ncol(x)\r\n      n.obs <- nrow(x)\r\n      if(!is.matrix(x)) x <- as.matrix(x)\r\n      nvar <- ncol(x)\r\n      Sx <- cov(x,use=\"pairwise\")\r\n      Sx.inv <- solve(Sx)\r\n      # Mx <- colMeans(x,na.rm=na.rm)\r\n      # x <- sweep(x,2,Mx)\r\n      #x <- t(scale(t(x),scale=FALSE))\r\n      x <- scale(x,scale=FALSE)\r\n      D2 <- t(apply(x,1,function(xx) colSums(xx * Sx.inv,na.rm=TRUE)))\r\n      D2 <- rowSums(D2*x,na.rm=TRUE)\r\n      names(D2) <- rn\r\n      \r\n      if(plot) {\r\n        Chi2 <- qchisq(ppoints(n.obs), df =  nvar)\r\n        qqplot(Chi2, D2,\r\n               main = expression(\"Q-Q plot of Mahalanobis\" * ~D^2 *\r\n                                   \" vs. quantiles of\" * ~ chi[nvar]^2),xlab=xlab,ylab=ylab,...)\r\n        abline(0, 1, col = 'gray')\r\n        worst <- order(D2,decreasing=TRUE)\r\n        text(Chi2[n.obs:(n.obs-bad+1)],D2[worst[1:bad]],names(D2)[worst[1:bad]],pos=3,...)\r\n      }\r\n      return(D2)\r\n    }\r\n  \r\n  #remove rows with all NA and issue warning\r\n  complete.na <- apply(x, 1, function(y) { all(is.na(y)) } )\r\n  if(any(complete.na)) {\r\n    warning(\"Some cases contain only NA values. The Mahalanobis distance will be calculated using available cases.\",\r\n            call. = FALSE) }\r\n  x_filtered <- x[!complete.na,]\r\n  \r\n  maha_data <- as.numeric(outlier(x_filtered, plot, bad = 0, na.rm = na.rm))\r\n  d_sq <- rep_len(NA, nrow(x_filtered))\r\n  d_sq[!complete.na] <- maha_data\r\n  \r\n  if(flag == TRUE) {\r\n    cut <- stats::qchisq(confidence, ncol(x))\r\n    flagged <- (d_sq > cut)\r\n    return(data.frame(d_sq = d_sq, flagged = flagged))\r\n  }\r\n  else{ return(d_sq) }\r\n}\r\n\r\n# IRV function (from careless package)\r\nirv <- function(x, na.rm = TRUE, split = FALSE, num.split = 3) {\r\n  out <- apply(x, 1, stats::sd, na.rm = na.rm)\r\n  \r\n  if(split == TRUE) {\r\n    chunk <- function(x,n) split(x, cut(seq_along(x), n, labels = FALSE))\r\n    split_x <- apply(x, 1, chunk, num.split)\r\n    out_split <- t(replicate(nrow(x), rep(NA, num.split)))\r\n    colnames(out_split) <- paste0(\"irv\",1:num.split)\r\n    for(k in 1:nrow(out_split)) {\r\n      split_x_single <- split_x[[k]]\r\n      out_split[k,] <- unlist(lapply(split_x_single, stats::sd, na.rm = na.rm), use.names = FALSE)\r\n    }\r\n    out_split <- data.frame(out, out_split)\r\n    colnames(out_split)[1] <- \"irvTotal\"\r\n    return(out_split)} else { #split subsection end\r\n      return(out)\r\n    }\r\n}\r\n\r\n# Longstring function (from careless package)\r\nlongstring <- function(x, avg=FALSE) {\r\n  \r\n  # subfunction that calculates the length of consecutive identical responses\r\n  rle_string <- function(x) {\r\n    rle_list <- rle(x)\r\n    longstr <- max(rle_list$lengths)\r\n    avgstr <- mean(rle_list$lengths)\r\n    return(cbind(longstr, avgstr))\r\n  }\r\n  \r\n  # apply the subfunctions to each row (case, subject)\r\n  output <- apply(x, 1, rle_string)\r\n  output <- data.frame(t(output))\r\n  colnames(output) <- (c('longstr','avgstr'))\r\n  \r\n  if(avg == TRUE) {\r\n    return(output)\r\n  } else {\r\n    return(output[,'longstr'])\r\n  }\r\n}\r\n\r\n#Longstring number of times 7 or more consecutive identical responses (modified from longstring in careless package)\r\nlongstring_n_times <- function(x, avg=FALSE, threshold=6) {\r\n  \r\n  # subfunction that calculates the length of consecutive identical responses\r\n  rle_string <- function(x) {\r\n    rle_list <- rle(x)\r\n    longstr <- max(rle_list$lengths)\r\n    avgstr <- mean(rle_list$lengths)\r\n    count_longstr <- sum(rle_list$lengths > threshold)\r\n    return(cbind(longstr, avgstr, count_longstr))\r\n  }\r\n  \r\n  # apply the subfunctions to each row (case, subject)\r\n  output <- apply(x, 1, rle_string)\r\n  output <- data.frame(t(output))\r\n  colnames(output) <- c('longstr','avgstr', 'count_longstr')\r\n  \r\n  if(avg == TRUE) {\r\n    return(output)\r\n  } else {\r\n    return(output[, c('longstr', 'count_longstr')])\r\n  }\r\n}\r\n\r\n# Psych synonyms function (from careless package)\r\npsychsyn <- function(x, critval=.60, anto=FALSE, diag=FALSE, resample_na=TRUE) {\r\n  x <- as.matrix(x)\r\n  item_pairs <- get_item_pairs(x, critval, anto)\r\n  \r\n  synonyms <- apply(x,1,syn_for_one, item_pairs, resample_na)\r\n  synonyms_df <- as.data.frame(aperm(synonyms))\r\n  colnames(synonyms_df) <- c(\"numPairs\", \"cor\")\r\n  \r\n  if(diag==TRUE) { return(synonyms_df) }\r\n  else { return(synonyms_df$cor) }\r\n}\r\n\r\n# Helper function that identifies psychometric synonyms in a given dataset\r\nget_item_pairs <- function(x, critval=.60, anto=FALSE) {\r\n  critval <- abs(critval) #Dummy Proofing\r\n  \r\n  correlations <- stats::cor(x, use = \"pairwise.complete.obs\")\r\n  correlations[upper.tri(correlations, diag=TRUE)] <- NA\r\n  correlations <- as.data.frame(as.table(correlations))\r\n  \r\n  # Identifying item pairs differs depending on whether the user wants\r\n  # Psychometric Synonyms or Psychometric Antonyms\r\n  if(anto==FALSE) {\r\n    item_pair_names <- correlations[which(correlations$Freq > critval, arr.ind=TRUE),c(1,2)]\r\n    if(nrow(item_pair_names)==0) {\r\n      stop(\"No Psychometric Synonyms found.\")\r\n    }\r\n  }\r\n  else if(anto==TRUE) {\r\n    item_pair_names <- correlations[which(correlations$Freq < -critval, arr.ind=TRUE),c(1,2)]\r\n    if(nrow(item_pair_names)==0) {\r\n      stop(\"No Psychometric Antonyms found.\")\r\n    }\r\n  }\r\n  \r\n  matches <- item_pair_names\r\n  return(matches)\r\n}\r\n\r\n# Helper function to calculate the within person correlation for a single individual\r\nsyn_for_one <- function(x, item_pairs, resample_na) {\r\n  item_pairs_omit_na <- which(!(is.na(x[item_pairs[,1]]) | is.na(x[item_pairs[,2]])))\r\n  sum_item_pairs <- length(item_pairs_omit_na)\r\n  #only execute if more than two item pairs\r\n  if(sum_item_pairs > 2) {\r\n    itemvalues <- cbind(as.numeric(x[as.numeric(item_pairs[,1])]), as.numeric(x[as.numeric(item_pairs[,2])]))\r\n    \r\n    # helper that calculates within-person correlation\r\n    psychsyn_cor <- function(x) {\r\n      suppressWarnings(stats::cor(x, use = \"pairwise.complete.obs\", method = \"pearson\")[1,2])\r\n    }\r\n    \r\n    # if resample_na == TRUE, re-calculate psychsyn should a result return NA\r\n    if(resample_na == TRUE) {\r\n      counter <- 1\r\n      synvalue <- psychsyn_cor(itemvalues)\r\n      while(counter <= 10 & is.na(synvalue)) {\r\n        itemvalues <- t(apply(itemvalues, 1, sample, 2, replace = F))\r\n        synvalue <- psychsyn_cor(itemvalues)\r\n        counter = counter+1\r\n      }\r\n    } else {\r\n      synvalue <- psychsyn_cor(itemvalues) # executes if resample_na == FALSE\r\n    }\r\n    \r\n  } else {synvalue <- NA} # executes if insufficient item pairs\r\n  \r\n  return(c(sum_item_pairs, synvalue))\r\n}","type":"text"}]
