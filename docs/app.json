[{"name":"app.R","content":"library(shiny)\r\nlibrary(dplyr)\r\nlibrary(reactable)\r\nlibrary(bslib)\r\n\r\n# Source the helper functions\r\nsource(\"helpers.R\")\r\nsource(\"library_functions.R\")\r\n\r\n# UI definition\r\nui <- fluidPage(\r\n  theme = bslib::bs_theme(\r\n    primary = \"#007BFF\",\r\n    secondary = \"#6C757D\"\r\n  ),\r\n  tags$head(\r\n    tags$style(HTML(\"\r\n      .shiny-input-container {  \r\n        font-family: 'IBM Plex Sans', sans-serif;\r\n      }\r\n      .icon {\r\n        font-size: 24px;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .footer {\r\n        font-size: 12px;\r\n        color: #6C757D;\r\n        margin-top: 20px;\r\n        text-align: right;\r\n      }\r\n      .header {\r\n        display: flex;\r\n        align-items: center;\r\n        margin-bottom: 20px;\r\n      }\r\n      .header img {\r\n        margin-right: 10px;\r\n      }\r\n      .safety-icon {\r\n        font-size: 24px;\r\n        color: #28a745;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .overview-icon {\r\n        font-size: 24px;\r\n        color: #007BFF;\r\n        vertical-align: middle;\r\n        margin-right: 10px;\r\n      }\r\n      .main-title {\r\n        font-size: 36px;\r\n        font-weight: bold;\r\n        text-align: left;\r\n        margin-bottom: 20px;\r\n      }\r\n    \"))\r\n  ),\r\n  \r\n  # Main header with the title\r\n  div(\r\n    class = \"header\",\r\n    div(\r\n      style = \"background: linear-gradient(to right, #007BFF, #6C757D);\r\n              padding: 10px; border-radius: 8px; display: inline-block;\",\r\n      h1(\r\n        style = \"font-family: 'IBM Plex Sans', sans-serif;\r\n                 color: white; font-weight: bold;\r\n                 text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4);\",\r\n        \"Detecting Low-Effort IR Survey Responses\"\r\n      )\r\n    )\r\n  ),\r\n  \r\n  \r\n  \r\n  sidebarLayout(\r\n    sidebarPanel(\r\n      selectInput(\"surveySelect\", \"Select your survey\", \r\n                  choices = c(\"NSSE\" = \"National Survey of Student Engagement (NSSE)\")),\r\n      fileInput(\"file\", \"Upload the raw data file (.csv, .xlsx):\"),\r\n      actionButton(\"run\", \"Run\")#,\r\n      #downloadButton(\"downloadData\", \"Download Data\")\r\n    ),\r\n    mainPanel(\r\n      tabsetPanel(\r\n        tabPanel(\"Overview\",\r\n                 uiOutput(\"analysisCompleteOverview\"),\r\n                 HTML(\"<div style='margin-top: 20px;'>\r\n        <p><span class='overview-icon' style='font-size: 150%;'>&#128200;<\/span> This dashboard is a free tool designed to flag and remove low-effort responses on higher education surveys like the NSSE.<\/p>\r\n        <p><span class='safety-icon' style='font-size: 150%;'>&#128274;<\/span> This tool is deployed using <a href='https://shiny.posit.co/py/docs/shinylive.html' target='_blank'>ShinyLive<\/a>, ensuring your data are processed locally and remain secure.<\/p>\r\n        <p><span class='process-icon' style='font-size: 150%;'>&#128187;<\/span> How does this work? Import your <b>raw<\/b> data file for the survey provided by the organization running the survey - <a href='#' onclick='alert(\\\"Details on how to prepare your data file go here.\\\");'>click here for details<\/a>.<\/p>\r\n    <\/div>\")\r\n        ),\r\n        tabPanel(\"Summary\",\r\n                 tags$div(\r\n                   tags$br(),  # Add a line break here\r\n                   tags$h3(style = \"font-weight: bold;\", \"Survey Response Summary\"),\r\n                   tags$p(style = \"font-size: 18px; font-weight: bold; color: #2E86C1;\", uiOutput(\"summaryText\")),\r\n                   tags$br(), tags$br(),  # Add two line breaks here\r\n                   tags$h3(style = \"font-weight: bold;\", \"Summary Table\"),\r\n                   reactableOutput(\"summaryTable\")\r\n                 )\r\n        ),\r\n\r\n        tabPanel(\"Explore Data\",\r\n                 selectInput(\"dataViewSelect\", \"See Low-Effort Responses for:\",\r\n                             choices = c(\"Filter 1: Survey Duration\" = \"Completed survey in 3 minutes or less\",\r\n                                         \"Filter 2: Skipped Questions\" = \"Skipped over 25% of survey questions\",\r\n                                         \"Filter 3: Straightlined 15 Responses\" = \"Straightlined 15 Responses\",\r\n                                         \"Filters 4 & 5: Repeated Straightline Behavior\" = \"Repeated Straightline Behavior\",\r\n                                         \"Filter 6: Other Repetitive Behavior\" = \"Other Repetitive Behavior\",\r\n                                         \"Filter 7: Unrealistic Quantitative Responses\" = \"Unrealistic Quantitative Responses\")),\r\n                 HTML(\"<p><i>This table displays respondents who were flagged for this particular issue, suggesting a low-effort response.<\/i><\/p>\"),\r\n                 reactableOutput(\"individualExamplesTable\")\r\n        ),\r\n        tabPanel(\"Download Data\",\r\n                 HTML(\"<div style='margin-top: 20px;'>\r\n                        <h2>&#128190; Download Data<\/h2>\r\n                        <p>The 'Download Data' exports a file containing your raw data with the addition of new columns indicating if (and why) the respondent was flagged as a low-effort responder.<\/p>\r\n                      <\/div>\"),\r\n                 downloadButton(\"downloadData\", \"Download Data\")\r\n        ),\r\n        tabPanel(\"About\",\r\n                 HTML(\"<h2 style='font-weight: bold;'>About this Tool<\/h2>\r\n        <p>This is an 'opinionated' tool: it decides what responses qualify as 'low effort' or not based on subjectively selected criteria. Our tool uses a sequential screening method to exclude respondents whose behavior may suggest a low-effort response. The table above provides a summary of your results from the raw data file. <a href='methodology_link_here'>More details on the methodology can be found here.<\/a><\/p>\r\n        <p>You can view the source code at Steve's <a href='https://github.com/stevensherrin' target='_blank'>GitHub page<\/a>. You are allowed to use and improve it, but not for any commercial purposes.<\/p>\")\r\n        )\r\n        \r\n        \r\n      )\r\n    )\r\n  ),\r\n  div(class = \"footer\",\r\n      HTML(\"<p>This dashboard was created by <a href='https://www.linkedin.com/in/steven-sherrin' target='_blank'>Steven Sherrin<\/a>. Research was conducted by <a href='https://www.linkedin.com/in/ingerbergom' target='_blank'>Inger Bergom<\/a> (Harvard University) and <a href='https://www.linkedin.com/in/steven-sherrin' target='_blank'>Steven Sherrin<\/a> (Wentworth Institute of Technology).<\/p>\")\r\n  )\r\n)\r\n\r\n# Server logic\r\nserver <- function(input, output, session) {\r\n  data <- reactiveVal()\r\n  \r\n  \r\n  observeEvent(input$run, {\r\n    req(input$file)\r\n    \r\n    # Read the uploaded file\r\n    df <- read_uploaded_file(input$file)\r\n    \r\n    # Check for missing variables\r\n    missing_vars <- check_missing_vars(df)\r\n    \r\n    # Show screen if any variables are missing\r\n    if (length(missing_vars) > 0) {\r\n      showModal(modalDialog(\r\n        title = \"Missing Variables\",\r\n        paste(missing_vars, collapse = \", \"),\r\n        easyClose = TRUE,\r\n        footer = modalButton(\"OK\")\r\n      ))\r\n    }\r\n  })\r\n  \r\n  observeEvent(input$run, {\r\n    req(input$file)\r\n    \r\n    # Remove recoded or estimated variables not used in the analysis\r\n    df <- remove_recoded_vars(df)\r\n    \r\n    # Clean the uploaded data\r\n    df <- clean_data(df)\r\n    \r\n    # Identify careless responses\r\n    df <- identify_careless_responses(df)\r\n    \r\n    # Process the summary table data\r\n    summary_df <- calculate_summary(df)\r\n    data(summary_df)\r\n    \r\n    # Let user know analysis is complete\r\n    output$analysisCompleteOverview <- renderUI({\r\n      HTML(\"<h3 style='font-size: 16px; border: 1px dotted pink; padding: 10px; font-weight: bold;'><br>Analysis of your data is complete! To see a summary table of your results, go to 'Summary'. To see individual responses, go to 'Explore Data'. To download your data, go to 'Download Data'.<\/h3>\")\r\n    })\r\n    \r\n    output$analysisComplete <- renderUI({\r\n      HTML(\"<h3 style='font-size: 16px; border: 1px dotted pink; padding: 10px; font-weight: bold;'><br>Analysis of your data is complete! To see a summary table of your results, go to 'Summary'. To see individual responses, go to 'Explore Data'. To download your data, go to 'Download Data'.<\/h3>\")\r\n    })\r\n    \r\n    \r\n    # Render summary text\r\n    output$summaryText <- renderText({\r\n      max_val <- max(data()$`Total Remaining Respondents`)\r\n      min_val <- min(data()$`Total Remaining Respondents`)\r\n      filtered_out <- max_val - min_val\r\n      percent_flagged <- (filtered_out / max_val) * 100\r\n      paste0(\"You started with <b style='text-decoration: underline double;'>\", max_val, \"<\/b> respondents. After we searched for low-effort responses, we identified and removed <b style='text-decoration: underline double;'>\", \r\n             filtered_out, \"<\/b> respondents (<b style='text-decoration: underline double;'>\", round(percent_flagged, 1), \"% of total<\/b>). You now have <b style='text-decoration: underline double;'>\", min_val, \"<\/b> remaining responses. For details on why respondents were removed, see the table below. For methodology details, see About.\")\r\n    })\r\n    \r\n    \r\n    # Render summary table\r\n    output$summaryTable <- renderReactable({\r\n      req(data())\r\n      \r\n      modified_data <- data()[-1, ]  # Remove the first row\r\n      \r\n      reactable(\r\n        modified_data,\r\n        columns = list(\r\n          Criteria = colDef(\r\n            name = \"\",\r\n            cell = function(value) {\r\n              div(style = list(fontStyle = \"italic\"), value)\r\n            },\r\n            headerStyle = list(verticalAlign = \"top\"),  # Align header to bottom\r\n            minWidth = 350, maxWidth = 350\r\n          ),\r\n          `Total Remaining Respondents` = colDef(\r\n            name = \"Total Remaining Respondents\",\r\n            headerStyle = list(textAlign = \"center\"),\r\n            style = list(textAlign = \"center\"),\r\n            minWidth = 150, maxWidth = 150\r\n          ),\r\n          `Total Respondents Excluded` = colDef(\r\n            name = \"Number of Respondents Excluded due to this Step\",\r\n            headerStyle = list(textAlign = \"center\"),\r\n            style = list(textAlign = \"center\"),\r\n            minWidth = 150, maxWidth = 150\r\n          ),\r\n          `Percentage of Total Respondents Removed` = colDef(\r\n            name = \"Percent of Respondents Excluded due to this Step\",\r\n            headerStyle = list(textAlign = \"center\"),\r\n            format = colFormat(percent = TRUE, digits = 1),\r\n            style = list(textAlign = \"center\"),\r\n            minWidth = 150, maxWidth = 150\r\n            \r\n          )\r\n        ),\r\n        rowStyle = function(index) {\r\n          if (index == nrow(modified_data)) {\r\n            list(\r\n              background = \"darkred\",  # dark red background\r\n              color = \"white\",\r\n              fontWeight = \"bold\",\r\n              border = \"2px solid #cc0000\",  # border to further highlight\r\n              width = \"100%\"\r\n            )\r\n          } else {\r\n            NULL\r\n          }\r\n        }\r\n      )\r\n    })\r\n    \r\n    \r\n    \r\n    # output$diagram <- renderDiagrammeR({\r\n    #   generate_diagram(summary_df)\r\n    # })\r\n    \r\n    \r\n    # Render Explore Data table\r\n    output$individualExamplesTable <- renderReactable({\r\n      req(data()) # Ensure data is loaded\r\n      \r\n      if (input$dataViewSelect == \"Completed survey in 3 minutes or less\") {\r\n        process_individual_examples(df, \"Completed survey in 3 minutes or less\")\r\n        columns <- colnames(step_1_filtered)\r\n        \r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          if (col == \"Duration (minutes)\") {\r\n            colDef(\r\n              cell = function(value) {\r\n                if (!is.na(value) && value <= 3) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            )\r\n          } else {\r\n            colDef(\r\n              headerStyle = list(textAlign = \"center\"),\r\n              style = list(textAlign = \"center\")\r\n            )\r\n          }\r\n        }), columns)\r\n        \r\n        reactable(step_1_filtered, defaultPageSize = 10, columns = column_defs, \r\n                  style = list(width = \"75%\")) # Limit the width of the table because it's only two columns\r\n        \r\n      } else if (input$dataViewSelect == \"Skipped over 25% of survey questions\") {\r\n        process_individual_examples(df, \"Skipped over 25% of survey questions\")\r\n        columns <- colnames(step_2_filtered) # Get the column names of the data\r\n        \r\n        # Create a named list of column definitions\r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          colDef(\r\n            cell = function(value) {\r\n              if (col == \"Percentage of Missing Values\") {\r\n                if (!is.na(value) && value >= 25) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              } else {\r\n                if (is.na(value)) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\")\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            },\r\n            headerStyle = list(textAlign = \"center\"),\r\n            style = list(textAlign = \"center\")\r\n          )\r\n        }), columns)\r\n        \r\n        reactable(step_2_filtered, defaultPageSize = 10, columns = column_defs)\r\n        \r\n      }\r\n      \r\n      else if (input$dataViewSelect == \"Straightlined 15 Responses\") {\r\n        process_individual_examples(df, \"Straightlined 15 Responses\")\r\n        columns <- colnames(step_3_values) # Get the column names of the data\r\n        \r\n        # Create a named list of column definitions with specific styling for \"Straightline Length\" column\r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          if (col == \"Straightline Length\") {\r\n            colDef(\r\n              cell = function(value) {\r\n                if (!is.na(value) && value >= 15) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            )\r\n          } else {\r\n            colDef(\r\n              headerStyle = list(textAlign = \"center\"),\r\n              style = list(textAlign = \"center\")\r\n            )\r\n          }\r\n        }), columns)\r\n        \r\n        reactable(step_3_values, defaultPageSize = 10, columns = column_defs)\r\n      }\r\n      \r\n      else if (input$dataViewSelect == \"Repeated Straightline Behavior\") {\r\n        process_individual_examples(df, \"Repeated Straightline Behavior\")\r\n        columns <- colnames(step_4_values) # Get the column names of the data\r\n        \r\n        # Create a named list of column definitions with specific styling for the specified columns\r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          if (col %in% c(\"# of Times Straightlined 7 or More Responses\", \"# of Subscales Straightlined\")) {\r\n            colDef(\r\n              cell = function(value) {\r\n                if (!is.na(value) && value >= 3) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            )\r\n          } else {\r\n            colDef(\r\n              headerStyle = list(textAlign = \"center\"),\r\n              style = list(textAlign = \"center\")\r\n            )\r\n          }\r\n        }), columns)\r\n        \r\n        reactable(step_4_values, defaultPageSize = 10, columns = column_defs)\r\n      }\r\n      \r\n      else if (input$dataViewSelect == \"Other Repetitive Behavior\") {\r\n        process_individual_examples(df, \"Other Repetitive Behavior\")\r\n        columns <- colnames(step_6_values) # Get the column names of the data\r\n        \r\n        # Create a named list of column definitions with specific styling for the specified columns\r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          if (col %in% c(\"Flagged for Repetitive Behavior\")) {\r\n            colDef(\r\n              cell = function(value) {\r\n                if (!is.na(value) && value == 1) {\r\n                  div(style = \"background-color: lightcoral; height: 100%; width: 100%;\", value)\r\n                } else {\r\n                  value\r\n                }\r\n              }\r\n            )\r\n          } else {\r\n            colDef(\r\n              headerStyle = list(textAlign = \"center\"),\r\n              style = list(textAlign = \"center\")\r\n            )\r\n          }\r\n        }), columns)\r\n        \r\n        reactable(step_6_values, defaultPageSize = 10, columns = column_defs)\r\n      }\r\n      \r\n      else if (input$dataViewSelect == \"Unrealistic Quantitative Responses\") {\r\n        process_individual_examples(df, \"Unrealistic Quantitative Responses\")\r\n        columns <- colnames(step_7_values) # Get the column names of the data\r\n        \r\n        column_defs <- setNames(lapply(columns, function(col) {\r\n          colDef(\r\n            headerStyle = list(textAlign = \"center\"),\r\n            style = list(textAlign = \"center\")\r\n          )\r\n        }), columns)\r\n        \r\n        reactable(step_7_values, defaultPageSize = 10, columns = column_defs)\r\n      }\r\n    })\r\n    \r\n    \r\n    # Allow download of processed data\r\n    output$downloadData <- downloadHandler(\r\n      filename = function() {\r\n        paste(\"nsse_survey_low_effort_responses_\", Sys.Date(), \".xlsx\", sep = \"\")\r\n      },\r\n      content = function(file) {\r\n        # Create a new workbook\r\n        new_wb <- createWorkbook()\r\n        \r\n        # Define styles\r\n        header_style <- createStyle(textDecoration = \"bold\", fontSize = 14)\r\n        text_style <- createStyle(fontSize = 12, wrapText = TRUE)\r\n        bullet_style <- createStyle(fontSize = 12, wrapText = TRUE, indent = 1)\r\n        \r\n        # Add \"About\" sheet with the specified text\r\n        addWorksheet(new_wb, \"About\")\r\n        \r\n        about_text <- c(\r\n          \"This Excel file has your data and results from the 'Detecting Low Effort Surveys' tool. It contains the following sheets:\",\r\n          \"\",\r\n          \"1. 'Your Summary': A table displaying the frequency (and percentage) of how often respondents exhibited behaviors indicating low-effort responding.\",\r\n          \"2. 'Your Data': Your data with new columns indicating which respondents should be removed from future analyses.\",\r\n          \"\",\r\n          \"If you have any questions, please contact Steve at stevensherrin@gmail.com with the title 'Detecting Low Effort Surveys'.\"\r\n        )\r\n        \r\n        # Write the \"About\" text to the first column\r\n        writeData(new_wb, \"About\", about_text, startCol = 1, startRow = 1)\r\n        \r\n        # Apply styles to the text\r\n        addStyle(new_wb, \"About\", header_style, rows = 1, cols = 1)\r\n        addStyle(new_wb, \"About\", text_style, rows = 2:2, cols = 1, gridExpand = TRUE)\r\n        addStyle(new_wb, \"About\", bullet_style, rows = 3:5, cols = 1, gridExpand = TRUE)\r\n        addStyle(new_wb, \"About\", text_style, rows = 6:6, cols = 1, gridExpand = TRUE)\r\n        \r\n        # Adjust column width to fit content\r\n        setColWidths(new_wb, \"About\", cols = 1, widths = 100)\r\n        \r\n        # Add the summary sheet with data\r\n        addWorksheet(new_wb, \"Your Summary\")\r\n        writeData(new_wb, \"Your Summary\", data())\r\n        \r\n        # Autofit the column widths for the \"Your Summary\" sheet\r\n        for (col in 1:ncol(data())) {\r\n          setColWidths(new_wb, \"Your Summary\", cols = col, widths = \"auto\")\r\n        }\r\n        \r\n        # Bold the top row of \"Your Summary\"\r\n        addStyle(new_wb, \"Your Summary\", header_style, rows = 1, cols = 1:ncol(data()), gridExpand = TRUE)\r\n        \r\n        # Style the last row of \"Your Summary\" with black fill and white font\r\n        last_row <- nrow(data()) + 1\r\n        last_row_style <- createStyle(fgFill = \"black\", fontColour = \"white\")\r\n        addStyle(new_wb, \"Your Summary\", last_row_style, rows = last_row, cols = 1:ncol(data()), gridExpand = TRUE)\r\n        \r\n        # Add a data sheet with detailed data\r\n        addWorksheet(new_wb, \"Your Data\")\r\n        \r\n        df2 <- df\r\n        df2 <- df2 %>% rename(`Row # in Original Data` = unique_id)\r\n        writeData(new_wb, \"Your Data\", df2)\r\n        \r\n        # Autofit the column widths for the \"Your Data\" sheet\r\n        for (col in 1:ncol(df)) {\r\n          setColWidths(new_wb, \"Your Data\", cols = col, widths = \"auto\")\r\n        }\r\n        \r\n        # Bold the column names of \"Your Data\"\r\n        addStyle(new_wb, \"Your Data\", header_style, rows = 1, cols = 1:ncol(df), gridExpand = TRUE)\r\n        \r\n        # Apply light blue background to the first two columns of \"Your Data\"\r\n        light_blue_style <- createStyle(fgFill = \"#ADD8E6\")\r\n        addStyle(new_wb, \"Your Data\", light_blue_style, rows = 1:nrow(df) + 1, cols = 1:2, gridExpand = TRUE)\r\n        \r\n        # Save the new workbook\r\n        saveWorkbook(new_wb, file, overwrite = TRUE)\r\n      }\r\n    )\r\n    \r\n    \r\n  })\r\n}\r\n\r\n# Run the application \r\nshinyApp(ui = ui, server = server)\r\n","type":"text"},{"name":"deploy_shinylive.R","content":"library(shinylive)\r\nlibrary(fs)\r\n#sessionInfo()\r\n\r\n# Define the path to your existing Shiny app\r\nexisting_app_path <- \"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Desktop/test - low effort - Copy/myapp\"\r\n\r\nshinylive::export(appdir = existing_app_path, destdir = \"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Desktop/test - low effort - Copy/myapp/docs\")\r\n\r\n#httpuv::runStaticServer(\"docs\")\r\n\r\nhttpuv::runStaticServer(\"C:/Users/sherrins/OneDrive - Wentworth Institute of Technology/Desktop/test - low effort - Copy/myapp/docs\")\r\n\r\n#httpuv::runStaticServer(\"docs/\", port=8008)\r\n\r\n\r\n","type":"text"},{"name":"helpers.R","content":"# Load necessary libraries\r\n#library(tidyverse)\r\nlibrary(openxlsx) #YES\r\nlibrary(writexl) #Yes\r\nlibrary(dplyr) #YES\r\nlibrary(tidyr) #YES\r\nlibrary(ggplot2) #YES\r\nlibrary(purrr) #YES\r\nlibrary(janitor) #YES\r\nlibrary(gtools) #YES\r\nlibrary(conflicted) #YES\r\nlibrary(reactable) #YES\r\nlibrary(scales) #YES\r\nlibrary(crosstalk) #YES\r\nlibrary(htmltools) #Yes\r\n\r\nconflicts_prefer(base::as.numeric())\r\nconflicts_prefer(base::is.character())\r\nconflicts_prefer(base::`&&`)\r\nconflicts_prefer(base::`||`)\r\nconflicts_prefer(dplyr::filter)\r\nconflicts_prefer(dplyr::lag)\r\n\r\ndone <- 0\r\n\r\n# List of required variables\r\nrequired_vars <- c(\r\n  \"askquest\", \"drafts\", \"unprepared\", \"attendart\",\r\n  \"CLaskhelp\", \"CLexplain\", \"CLstudy\", \"CLproject\", \"present\",\r\n  \"RIintegrate\", \"RIsocietal\", \"RIdiverse\", \"RIownview\", \"RIperspect\",\r\n  \"RInewview\", \"RIconnect\", \"SFcareer\", \"SFotherwork\", \"SFdiscuss\",\r\n  \"SFperform\", \"memorize\", \"HOapply\", \"HOanalyze\", \"HOevaluate\",\r\n  \"HOform\", \"ETgoals\", \"ETorganize\", \"ETexample\", \"ETdraftfb\",\r\n  \"ETfeedback\", \"QRconclude\", \"QRproblem\", \"QRevaluate\", \r\n  \"DDrace\", \"DDeconomic\", \"DDreligion\", \"DDpolitical\",\r\n  \"LSreading\", \"LSnotes\", \"LSsummary\",\r\n  \"challenge\", \"intern\", \"leader\", \"learncom\", \"abroad\",\r\n  \"research\", \"capstone\", \"servcourse\",\r\n  \"QIstudent\", \"QIadvisor\", \"QIfaculty\", \"QIstaff\", \"QIadmin\",\r\n  \"empstudy\", \"SEacademic\", \"SElearnsup\", \"SEdiverse\", \"SEsocial\", \"SEwellness\", \"SEnonacad\", \"SEactivities\", \"SEevents\",\r\n  \"pgwrite\", \"pgwspeak\",\"pgthink\", \"pganalyze\", \"pgwork\", \"pgothers\", \"pgvalues\", \"pgdiverse\", \"pgprobsolve\", \"pgcitizen\",\r\n  \"tmprephrs\",\"tmcocurrhrs\", \"tmworkonhrs\", \"tmworkoffhrs\", \"tmservicehrs\",\r\n  \"tmrelaxhrs\", \"tmcarehrs\", \"tmcommutehrs\", \"duration\"\r\n)\r\n\r\n# Function to check required variables\r\ncheck_missing_vars <- function(df) {\r\n  # Get the column names of the dataframe\r\n  df_columns <- colnames(df)\r\n  \r\n  # Check for the presence of specific required columns\r\n  missing_vars <- setdiff(required_vars, df_columns)\r\n  \r\n  # Print missing variables if any\r\n  if (length(missing_vars) > 0) {\r\n    print(paste(\"The following columns are missing from your raw NSSE file:\", \r\n                paste(missing_vars, collapse = \", \"), \r\n                \". Some of this may be due to analyzing a particular year from NSSE, especially older years. Keep in mind this may prevent the analysis from running properly.\"))\r\n  } else {\r\n    print(\"All required columns are present.\")\r\n  }\r\n  \r\n}\r\n\r\n# Function to remove recoded and estimated variables\r\n# (In some cases - such as hours per week questions - we do choose to keep the estimated variables and remove the original ones)\r\nremove_recoded_vars <- function(df) {\r\n  # Create list of possible variables to remove\r\n  # (This will depend on year of survey - not all variables will be present in all years)\r\n  recoded_vars <- c(\"unpreparedr\",\r\n                    \"wrshortnum\",\r\n                    \"wrmednum\",\r\n                    \"wrlongnum\",\r\n                    \"wrpages\",\r\n                    \"HIPsumFY\",\r\n                    \"HIPsumSR\",\r\n                    \"QIstudentR\",\r\n                    \"QIadvisorR\",\r\n                    \"QIfacultyR\",\r\n                    \"QIstaffR\",\r\n                    \"QIadminR\",\r\n                    \"tmprep\",\r\n                    \"tmcocurr\",\r\n                    \"tmworkon\",\r\n                    \"tmworkoff\",\r\n                    \"tmworkhrs\",\r\n                    \"tmservice\",\r\n                    \"tmrelax\",\r\n                    \"tmcare\",\r\n                    \"tmcommute\",\r\n                    \"tmread\",\r\n                    \"reading\",\r\n                    \"tmreadinghrscol\",\r\n                    \"wrshort\", # These \"wr\"/writing questions are wedged in the middle of the main page and have a different response scale. They are not used in the main analyses.\r\n                    \"wrmed\", # See above\r\n                    \"wrlong\",\r\n                    \"wrshortnum\",\r\n                    \"wrmednum\",\r\n                    \"wrlongnum\",\r\n                    \"wrpages\")\r\n  \r\n  # Remove recoded variables from the dataframe\r\n  df <- df %>%\r\n    select(-any_of(recoded_vars))\r\n  \r\n  print(\"Removed recoded and/or estimated variables not used in analyses.\")\r\n  \r\n  return(df)\r\n}\r\n\r\n# Function to read the uploaded file\r\nread_uploaded_file <- function(file) {\r\n  ext <- tools::file_ext(file$name)\r\n  if (ext == \"csv\") {\r\n    df <- read.csv(file$datapath)\r\n  } else if (ext == \"xlsx\") {\r\n    df <- read.xlsx(file$datapath)\r\n  } else {\r\n    stop(\"Invalid file type. Please upload a .csv or .xlsx file.\")\r\n  }\r\n  assign(\"df\", df, envir = .GlobalEnv)\r\n  return(df)\r\n}\r\n\r\n# Function to clean and prepare the dataframe\r\nclean_data <- function(df) {\r\n  # Clean column names\r\n  df <- clean_names(df)\r\n  print(\"Column names successfully cleaned\")\r\n  \r\n  # Check if all columns have valid names\r\n  na_or_empty_names <- which(is.na(names(df)) | names(df) == \"\")\r\n  \r\n  # Print columns that have invalid names; if there are none, say \"No columns with NA or empty names\"\r\n  if (length(na_or_empty_names) > 0) {\r\n    cat(\"Columns with NA or empty names:\", na_or_empty_names, \"\\n\")\r\n    # Assign new names to these columns, for example: V1, V2, etc.\r\n    names(df)[na_or_empty_names] <- paste(\"V\", na_or_empty_names, sep = \"\")\r\n  } else {\r\n    print(\"No columns with NA or empty names\")\r\n  }\r\n  \r\n  # Create a unique identifier for each row\r\n  df <- df %>%\r\n    mutate(unique_id = paste0(row_number()))\r\n  print(\"Unique identifier for each row created\")\r\n  \r\n  assign(\"df\", df, envir = .GlobalEnv)\r\n  return(df)\r\n}\r\n\r\n# Function to process the data for summary table\r\ncalculate_summary <- function(df) {\r\n  summary_df <- tibble(\r\n    Criteria = c(\"Responses in raw NSSE dataset\",\r\n                 \"Completed survey in 3 minutes or less\", \r\n                 \"Skipped over 25% of survey questions\",\r\n                 \"Straightlined 15 or more responses in a row\",\r\n                 \"Had 3 or more times they straightlined least 7 responses in a row\",\r\n                 \"Straightlined 3 or more scales\",\r\n                 \"Made repetitive pattern (e.g. AB-AB-AB) 50% or more of the time\",\r\n                 \"Unrealistic response to quantitative question (e.g. hours per week)\",\r\n                 \"Highly unusual responses to highly correlated items\"),\r\n    `Percentage of Total Respondents Removed` = c(\r\n      0,\r\n      abs(row_changes[1]) / nrow(df),\r\n      abs(row_changes[2]) / nrow(df),\r\n      abs(row_changes[3]) / nrow(df),\r\n      abs(row_changes[4]) / nrow(df),\r\n      abs(row_changes[5]) / nrow(df),\r\n      abs(row_changes[6]) / nrow(df),\r\n      abs(row_changes[7]) / nrow(df),\r\n      abs(row_changes[8]) / nrow(df)\r\n      \r\n    ),\r\n    `Total Respondents Excluded` = c(\r\n      0,\r\n      abs(row_changes[1]),\r\n      abs(row_changes[2]),\r\n      abs(row_changes[3]),\r\n      abs(row_changes[4]),\r\n      abs(row_changes[5]),\r\n      abs(row_changes[6]),\r\n      abs(row_changes[7]),\r\n      abs(row_changes[8])\r\n    ))\r\n    \r\n  summary_df <- summary_df %>%\r\n    mutate(`Total Remaining Respondents` = nrow(df) - cumsum(`Total Respondents Excluded`)) %>%\r\n    mutate(`Total Remaining Respondents` = replace(`Total Remaining Respondents`, 1, nrow(df)))\r\n  \r\n  summary_df <- summary_df %>%\r\n    select(Criteria, `Total Remaining Respondents`, everything())\r\n  \r\n  #Starting at row #2, add \"Filter/Step X: \" to the beginning of each Criteria. Start with step 1.\r\n  summary_df$Criteria[2:nrow(summary_df)] <- paste0(\"Filter/Step \", 1:(nrow(summary_df)-1), \": \", summary_df$Criteria[2:nrow(summary_df)])\r\n\r\n  #Create a summary row with the sums, except for \"Total Remaining Respondents\", which is the last found value for that column\r\n  summary_df <- summary_df %>%\r\n    bind_rows(\r\n      tibble(\r\n        Criteria = \"Final\",\r\n        `Percentage of Total Respondents Removed` = sum(summary_df$`Percentage of Total Respondents Removed`),\r\n        `Total Respondents Excluded` = sum(summary_df$`Total Respondents Excluded`),\r\n        `Total Remaining Respondents` = summary_df$`Total Remaining Respondents`[[nrow(summary_df)]]\r\n      )\r\n    )\r\n  \r\n  assign(\"summary_df\", summary_df, envir = .GlobalEnv)\r\n  return(summary_df)\r\n}\r\n\r\n# Function to generate DiagrammeR graph\r\n# generate_diagram <- function(summary_df) {\r\n  # summary_df <- summary_df %>%\r\n  #   mutate(label = paste0(Criteria, \"\\nExcluded: \", Excluded, \"\\nRemaining: \", Remaining))\r\n  # \r\n  # nodes <- paste0(\r\n  #   \"node [shape = box, style = filled, fillcolor = LightSkyBlue]\",\r\n  #   paste0(\"n\", 1:nrow(summary_df), \" [label = '\", summary_df$label, \"'];\", collapse = \"\\n\")\r\n  # )\r\n  # \r\n  # edges <- paste0(\r\n  #   paste0(\"n\", 1:(nrow(summary_df)-1), \" -> n\", 2:nrow(summary_df), \";\", collapse = \"\\n\")\r\n  # )\r\n  # \r\n  # graph <- paste0(\r\n  #   \"digraph flowchart {\",\r\n  #   nodes, \"\\n\",\r\n  #   edges, \"\\n\",\r\n  #   \"}\"\r\n  # )\r\n  # \r\n  # return(grViz(graph))\r\n  \r\n  # design <- tibble::tribble(\r\n  #   ~left,               ~n_left, ~right,              ~n_right,\r\n  #   \"Study base\",        1000,    \"Not sampled\",       250,\r\n  #   \"Study population\",  750,     \"Participants with\\nmissing exposure data\", 100,\r\n  #   \"Complete-case set\", 650,     \"\",                  NA_integer_)\r\n  # \r\n  # # Plot\r\n  # exclusion_flowchart(design, width = 2)\r\n# }\r\n\r\n\r\n# Format summary table\r\nformat_percentage_cell <- function(value) {\r\n  # Ensure value is between 0 and 1 for percentages\r\n  value <- min(max(value, 0), 1)\r\n  # Rescale value to 0-1 range for gradient\r\n  gradientValue <- scales::rescale(value, c(0, 1), c(0, 1))\r\n  # Use the gradient value to interpolate between white and red\r\n  color <- colorRampPalette(c(\"white\", \"red\"))(100)[as.integer(gradientValue * 99) + 1]\r\n  style <- paste(\"background-color:\", color, \"; color: black;\") # Set font color to black\r\n  htmltools::span(style = style, scales::percent(value, accuracy = 0.1))\r\n}\r\n\r\n# Function to process individual examples based on selected view\r\nprocess_individual_examples <- function(df, view_select) {\r\n  if (view_select == \"Completed survey in 3 minutes or less\") {\r\n\r\n    step_1_filtered <- df %>%\r\n      select(unique_id, duration) %>%\r\n      mutate(duration = round(as.numeric(duration), 1)) %>%\r\n      arrange(duration)\r\n    \r\n    step_1_filtered <- step_1_filtered %>%\r\n      rename(\r\n        `Row in Dataset` = unique_id,\r\n        `Duration (minutes)` = duration\r\n      )\r\n    \r\n    # Add to global environment\r\n    assign(\"step_1_filtered\", step_1_filtered, envir = .GlobalEnv)\r\n    \r\n    return(step_1_filtered)\r\n    \r\n  } else if (view_select == \"Skipped over 25% of survey questions\") {\r\n    \r\n    step_2_filtered <- step_1 %>%\r\n      mutate(missing_percentage = round(rowSums(is.na(.)) / ncol(.) * 100),1)\r\n    \r\n    step_2_filtered <- step_2_filtered %>%\r\n      select(missing_percentage, unique_id, everything())\r\n    \r\n    step_2_filtered <- step_2_filtered %>%\r\n      arrange(desc(missing_percentage))\r\n    \r\n    step_2_filtered <- step_2_filtered %>%\r\n      rename(\r\n        `Row in Dataset` = unique_id,\r\n        `Percentage of Missing Values` = missing_percentage\r\n      )\r\n    \r\n\r\n    # Add to global environment\r\n    assign(\"step_2_filtered\", step_2_filtered, envir = .GlobalEnv)\r\n    \r\n    return(step_2_filtered)\r\n  }\r\n  \r\n  \r\n  else if (view_select == \"Straightlined 15 Responses\") {\r\n    \r\n    step_3_values <- step_3_values %>%\r\n      arrange(desc(longstring)) %>%\r\n      rename(`Row in Dataset` = unique_id,\r\n             `Straightline Length` = longstring)\r\n    \r\n    \r\n    # Add to global environment\r\n    assign(\"step_3_values\", step_3_values, envir = .GlobalEnv)\r\n    \r\n    return(step_3_values)\r\n  }\r\n  \r\n  else if (view_select == \"Repeated Straightline Behavior\") {\r\n    \r\n    step_4_values <- merge(step_4_values, step_5_values,\r\n                           by = \"unique_id\",\r\n                           all.x = TRUE)\r\n    \r\n    step_4_values <- step_4_values %>%\r\n      arrange(desc(longstring_7_or_more)) %>%\r\n      rename(`Row in Dataset` = unique_id,\r\n             `# of Times Straightlined 7 or More Responses` = longstring_7_or_more,\r\n             `# of Subscales Straightlined` = longstring_3_or_more_scales)\r\n    \r\n    step_4_values <- step_4_values %>%\r\n      select(`Row in Dataset`, \r\n             `# of Times Straightlined 7 or More Responses`, \r\n             `# of Subscales Straightlined`,\r\n             everything())\r\n    \r\n    step_4_values <- step_4_values %>% select(-longstring)\r\n    \r\n    # Add to global environment\r\n    assign(\"step_4_values\", step_4_values, envir = .GlobalEnv)\r\n    \r\n    return(step_4_values)\r\n  }\r\n  \r\n  else if (view_select == \"Other Repetitive Behavior\") {\r\n    step_6_values <- step_6_values %>%\r\n      arrange(desc(repetitive), desc(rp_2)) %>%\r\n      rename(`Row in Dataset` = unique_id,\r\n             `Flagged for Repetitive Behavior` = repetitive,\r\n             `% of Times Previous Response Repeated` = rp_2,\r\n             `% of Times 2nd Previous Response Repeated` = rp_3,\r\n             `% of Times 3rd Previous Response Repeated` = rp_4,\r\n             `% of Times 4th Previous Response Repeated` = rp_5) %>%\r\n      # Divide the variables with \"%\" in the name by 100 and then format as percentages\r\n      mutate(across(contains(\"%\"), ~ . / 100)) %>%\r\n      mutate(across(contains(\"%\"), ~ scales::percent(., accuracy = 0.1)))\r\n    \r\n    assign(\"step_6_values\", step_6_values, envir = .GlobalEnv)\r\n    \r\n    return(step_6_values)\r\n  }\r\n  \r\n  else if (view_select == \"Unrealistic Quantitative Responses\") {\r\n    step_7_values <- step_7_values %>%\r\n      arrange(desc(total_hours_per_week)) %>%\r\n      rename(`Row in Dataset` = unique_id,\r\n             `Total Hours per Week` = total_hours_per_week) %>%\r\n      mutate(`Flagged for Unrealistic Hours?` = ifelse( `Total Hours per Week` > 140, \"Yes\", \"No\")) %>%\r\n      mutate(`Total Hours per Week` = ifelse(is.na(`Total Hours per Week`), 0, `Total Hours per Week`)) %>%\r\n      select(`Row in Dataset`, `Total Hours per Week`, `Flagged for Unrealistic Hours?`, everything())\r\n    \r\n    assign(\"step_7_values\", step_7_values, envir = .GlobalEnv)\r\n    \r\n    return(step_7_values)\r\n  }\r\n  \r\n\r\n    \r\n}\r\n\r\n# Function to identify careless responses\r\nidentify_careless_responses <- function(df) {\r\n  \r\n  ############################################\r\n  ### Metrics for Main Page of NSSE Survey ###\r\n  ###########################################\r\n  \r\n  # Subsetting and transforming data for the first page of survey\r\n  df_main_page <- df %>%\r\n    select(unique_id, duration, askquest:s_eevents) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) # Convert all columns to numeric\r\n  \r\n  # Extracting unique IDs\r\n  first_page_ids <- df_main_page$unique_id\r\n  #df_main_page <- df_main_page %>% select(-unique_id)\r\n  \r\n  # Perform your specific analysis (placeholder for your functions)\r\n  # longstring, na measures, psychsyn, and mahad analysis\r\n  # Ensure these functions are defined or loaded from respective libraries\r\n  \r\n  #Step 1: Screen low duration\r\n  step_1 <- df_main_page %>%\r\n    filter(as.numeric(duration) > 3) %>%\r\n    select(-duration)\r\n  \r\n  print(\"Step 1 completed\")\r\n  \r\n  #Step 2: Screen for high number of missing values\r\n  step_2 <- step_1 %>%\r\n    filter(rowSums(is.na(step_1)) < 15)\r\n  \r\n  print(\"Step 2 completed\")\r\n  \r\n  #Step 3: Screen for longstrings of 15 or more\r\n  step_3 <- step_2 %>%\r\n    mutate(longstring = longstring(step_2)) \r\n  \r\n  step_3_values <- step_3 %>%\r\n    select(unique_id, longstring, everything())\r\n  \r\n  step_3 <- step_3 %>%\r\n    filter(longstring < 15)\r\n  \r\n  print(\"Step 3 completed\")\r\n  \r\n  #Step 4: Screen for repeated longstrings of more than 6\r\n  step_4 <- step_3 %>%\r\n    mutate(longstring_7_or_more = longstring_n_times(step_3, threshold = 6)$count_longstr) \r\n  \r\n  step_4_values <- step_4 %>%\r\n    select(unique_id, longstring_7_or_more, everything())\r\n  \r\n  step_4 <- step_4 %>%\r\n    filter(longstring_7_or_more < 3)\r\n  \r\n  print(\"Step 4 completed\")\r\n  \r\n  #Step 5: Screen for respondents who answer 3 or more scales with 0 variance\r\n  #Calculate longstrings for each question set (\"q_set_\") and return the number \"1\" if the longstring equals the number of responses\r\n  # Define question sets\r\n  question_sets <- list(\r\n    q_set_1 = c(\"askquest\", \"c_laskhelp\", \"c_lexplain\", \"c_lstudy\", \"c_lproject\", \"present\"),\r\n    q_set_2 = c(\"r_iintegrate\", \"r_isocietal\", \"r_idiverse\", \"r_iownview\", \"r_iperspect\", \"r_inewview\", \"r_iconnect\"),\r\n    q_set_3 = c(\"memorize\", \"h_oapply\", \"h_oanalyze\", \"h_oevaluate\", \"h_oform\"),\r\n    q_set_4 = c(\"e_tgoals\", \"e_torganize\", \"e_texample\", \"e_tdraftfb\", \"e_tfeedback\", \"e_tcriteria\", \"e_treview\", \"e_tprefer\", \"e_tdemonstrate\"),\r\n    q_set_5 = c(\"d_drace\", \"d_deconomic\", \"d_dreligion\", \"d_dpolitical\", \"d_dsexorient\", \"d_dcountry\"),\r\n    q_set_6 = c(\"intern\", \"leader\", \"learncom\", \"abroad\", \"research\", \"capstone\", \"servcourse\"),\r\n    q_set_7 = c(\"empstudy\", \"s_eacademic\", \"s_elearnsup\", \"s_ediverse\", \"s_esocial\", \"s_ewellness\", \"s_enonacad\", \"s_eactivities\", \"s_eevents\"),\r\n    q_set_8 = c(\"tmprephrs\", \"tmcocurrhrs\", \"tmworkonhrs\", \"tmworkoffhrs\", \"tmservicehrs\", \"tmrelaxhrs\", \"tmcarehrs\", \"tmcommutehrs\")\r\n  )\r\n  \r\n  # Add variables from question sets to dataframe (if not already present)\r\n  vars_in_question_sets <- unique(unlist(question_sets))\r\n  \r\n  # Convert unique_id in step_4 and df to character\r\n  step_4$unique_id <- as.character(step_4$unique_id)\r\n  df$unique_id <- as.character(df$unique_id)\r\n  \r\n  step_5 <- step_4 %>%\r\n    left_join(df %>% select(unique_id, any_of(vars_in_question_sets)), by = \"unique_id\", suffix = c(\"\", \".df\")) %>%\r\n    select(-ends_with(\".df\"))\r\n  \r\n  # Function to calculate longstring ratio for a question set\r\n  calculate_longstring_ratio <- function(df, set_name, set_columns) {\r\n    df %>%\r\n      mutate(!!paste0(set_name, \"_longstring\") := as.numeric(longstring(select(., one_of(set_columns)))) / \r\n               rowSums(!is.na(select(., one_of(set_columns)))))\r\n  }\r\n  \r\n  # Iterate over all question sets and calculate longstring ratio\r\n  for (i in 1:length(question_sets)) {\r\n    set_name <- paste0(\"q_set_\", i)\r\n    set_columns <- question_sets[[set_name]]\r\n    step_5 <- calculate_longstring_ratio(step_5, set_name, set_columns)\r\n  }\r\n  \r\n  # Calculate the number of question sets with longstring ratio equal to 1\r\n  step_5 <- step_5 %>%\r\n    mutate(longstring_3_or_more_scales = rowSums(select(., starts_with(\"q_set_\")) == 1)) \r\n  \r\n  step_5_values <- step_5 %>%\r\n    select(unique_id, longstring_3_or_more_scales)\r\n  \r\n  step_5 <- step_5 %>%\r\n    filter(longstring_3_or_more_scales < 3)\r\n  \r\n  print(\"Step 5 completed\")\r\n\r\n  \r\n  #Step 6: Screen for 2-value repetitive pattern (e.g. AB-AB-AB)\r\n  # Keep only the columns found in df_main_page. (We'll add the other ones back later.)\r\n  #common_columns <- intersect(names(step_5), names(df_main_page))\r\n  \r\n  # step_6 <- step_5 %>%\r\n  #   select(all_of(common_columns), -unique_id)\r\n  \r\n  step_6 <- df %>%\r\n    select(unique_id, askquest:s_eevents) %>%\r\n    #keep only unique_ids found in step_5\r\n    filter(unique_id %in% step_5$unique_id) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) # Convert all columns to numeric\r\n\r\n  # Function to calculate percentage of repeated patterns\r\n  calculate_repeated_pattern_percentage <- function(data, lag) {\r\n    same_count <- rowSums(data == lag(data, n = lag, default = NA), na.rm = TRUE)\r\n    total_count <- rowSums(!is.na(data))\r\n    percentage <- (same_count / total_count) * 100\r\n    return(percentage)\r\n  }\r\n  \r\n  # Calculate percentages for different lags and store in new columns\r\n  step_6 <- step_6 %>%\r\n    mutate(rp_2 = calculate_repeated_pattern_percentage(across(everything()), 2),\r\n           rp_3 = calculate_repeated_pattern_percentage(across(everything()), 3),\r\n           rp_4 = calculate_repeated_pattern_percentage(across(everything()), 4),\r\n           rp_5 = calculate_repeated_pattern_percentage(across(everything()), 5))\r\n  \r\n  # If any of rp_2 to rp_5 is 50% or higher, flag the respondent\r\n  step_6 <- step_6 %>%\r\n    mutate(repetitive = ifelse(rowSums(select(., starts_with(\"rp_\")) >= 60) > 0, 1, 0))\r\n  \r\n  # Save step_6 before filtering\r\n  step_6_values <- step_6 %>%\r\n    select(unique_id, repetitive, contains(\"rp_\"), everything())\r\n  \r\n  # z <- step_6_values %>%\r\n  #   filter(repetitive == 1)\r\n  \r\n  # # Function to plot responses for a single respondent\r\n  # plot_responses <- function(responses, respondent_id, start_question, end_question) {\r\n  #   responses_subset <- responses[start_question:end_question]\r\n  #   responses_long <- data.frame(Question = names(responses_subset), Response = unlist(responses_subset))\r\n  #   responses_long <- responses_long[complete.cases(responses_long), ]\r\n  #   \r\n  #   ggplot(responses_long, aes(x = Response, y = factor(Question, levels = rev(names(responses_subset))))) +\r\n  #     geom_point(color = \"blue\", size = 3) +\r\n  #     geom_line(aes(group = 1), color = \"blue\") +\r\n  #     scale_x_continuous(breaks = 1:5, limits = c(1, 5)) +\r\n  #     theme(axis.text.y = element_text(angle = 0, hjust = 1)) +\r\n  #     ggtitle(paste(\"Responses for Respondent\", respondent_id, \"(Questions\", start_question, \"to\", end_question, \")\")) +\r\n  #     xlab(\"Response Option\") +\r\n  #     ylab(\"Questions\") +\r\n  #     theme_minimal()\r\n  # }\r\n  # \r\n  # # Loop through the respondents to generate the plots, 25 questions per page\r\n  # questions_per_page <- 25\r\n  # total_questions <- ncol(z)\r\n  # \r\n  # for (respondent_id in 1:nrow(z)) {\r\n  #   num_pages <- ceiling(total_questions / questions_per_page)\r\n  #   for (page in 1:num_pages) {\r\n  #     start_question <- (page - 1) * questions_per_page + 1\r\n  #     end_question <- min(page * questions_per_page, total_questions)\r\n  #     pdf(paste0(\"respondent_\", respondent_id, \"_page_\", page, \".pdf\"))\r\n  #     print(plot_responses(z[respondent_id, , drop = FALSE], respondent_id, start_question, end_question))\r\n  #     dev.off()\r\n  #   }\r\n  # }\r\n  \r\n  # Filter out respondents with repetitive patterns\r\n  step_6 <- step_6 %>%\r\n    filter(repetitive == 0 | is.na(repetitive) == TRUE)\r\n  \r\n  print(\"Step 6 completed\")\r\n  \r\n  # step_6_filtered <- step_6[, !grepl(\"^rp_\", colnames(step_6))]\r\n  # step_6_filtered <- step_6 %>% select(-unique_id)\r\n  # rep_pattern_algo = rp.patterns(step_6_filtered)\r\n  # indices <- rp.indices(rep_pattern_algo, include.coefs = FALSE)\r\n  # \r\n  # rp.plot(rep_pattern_algo, obs = 105)\r\n  \r\n  # Step 7: Screen for invalid responses to \"hours\" question set\r\n  # Create dataframe \"df_hours\" with variables found in list question_sets q_set_8\r\n  df_hours <- df %>%\r\n    select(unique_id, tmprephrs:tmcommutehrs) %>%\r\n    filter(unique_id %in% step_6$unique_id) %>%\r\n    #select(-unique_id) %>%\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) # Convert all columns to numeric\r\n  \r\n  # Calculate total hours per week\r\n  df_hours$total_hours_per_week <- rowSums(select(df_hours, -unique_id), na.rm = TRUE)\r\n  \r\n  # Add df_hours$total_hours_per_week to step_7 based on unique_id\r\n  step_7 <- step_6 %>%\r\n    left_join(df_hours, by = \"unique_id\")\r\n  \r\n  # Save results\r\n  step_7_values <- step_7 %>%\r\n    select(unique_id, total_hours_per_week, contains(\"tm\"))\r\n  \r\n  # Filter out respondents with unrealistic total hours per week\r\n  step_7 <- step_7 %>%\r\n    mutate(total_hours_per_week = ifelse(is.na(total_hours_per_week), 0, total_hours_per_week)) %>%\r\n    filter(total_hours_per_week <= 140)\r\n  \r\n  print(\"Step 7 completed\")\r\n\r\n  # Step 8: Screen for unusual responses to highly correlated items\r\n  step_8 <- df %>%\r\n    select(unique_id, askquest:sameinst) %>%\r\n    #keep only unique_ids found in step_6\r\n    filter(unique_id %in% step_7$unique_id) %>%\r\n    #convert all columns to numeric\r\n    mutate(across(everything(), ~ as.numeric(as.character(.)))) %>%\r\n    #Remove any columns with all NAs\r\n    select(where(~!all(is.na(.))))\r\n  \r\n  step_8_filtered <- step_8 %>%\r\n    select(-unique_id) #-tmworkhrs)\r\n  \r\n  #Scale all variables in step_7_filtered\r\n  step_8_filtered <- step_8_filtered %>%\r\n    mutate(across(everything(), scale))\r\n  \r\n  step_8$mv_syn <- psychsyn(step_8_filtered, critval = .50)\r\n  step_8$mv_mahad <- scale(mahad(step_8_filtered))\r\n  \r\n  #Remove any rows with Mahalanobis distance greater than 3 and synonym correlation below 0\r\n  step_8 <- step_8 %>%\r\n    filter(mv_mahad < 3 & mv_syn > 0)\r\n  \r\n  print(\"Step 8 completed\")\r\n  \r\n  #Compare the number of rows in each step\r\n  steps <- list(df, step_1, step_2, step_3, step_4, step_5, step_6, step_7, step_8)\r\n  \r\n  # Initialize an empty vector to store the changes\r\n  row_changes <- vector(\"numeric\", length = length(steps) - 1)\r\n  \r\n  # Loop through the dataframes to calculate the changes in number of rows\r\n  for (i in 1:(length(steps) - 1)) {\r\n    row_changes[i] <- nrow(steps[[i + 1]]) - nrow(steps[[i]])\r\n  }\r\n\r\n  assign(\"row_changes\", row_changes, envir = .GlobalEnv)\r\n  \r\n  # Find last step each respondent was included in\r\n  # Initialize a data frame to store the results\r\n  last_occurrence <- data.frame(unique_id = unique(df$unique_id), last_dataframe = NA)\r\n  \r\n  # Loop over each unique_id in df\r\n  for (i in seq_along(last_occurrence$unique_id)) {\r\n    unique_id <- last_occurrence$unique_id[i]\r\n    # Loop over each dataframe in reverse order\r\n    for (j in length(steps):1) {\r\n      if (unique_id %in% steps[[j]]$unique_id) {\r\n        last_occurrence$last_dataframe[i] <- paste(\"step\", j-1, sep = \"_\")\r\n        break\r\n      }\r\n    }\r\n  }\r\n  \r\n  # Recode the last_dataframe column\r\n  last_occurrence <- last_occurrence %>%\r\n    mutate(last_dataframe = recode(last_dataframe, \r\n                                   `step_0` = \"Completed survey in 3 minutes or less\",\r\n                                   `step_1` = \"Skipped over 25% of survey questions\",\r\n                                   `step_2` = \"Straightlined 15 or more responses in a row\",\r\n                                   `step_3` = \"Had 3 or more times they straightlined least 7 responses in a row\",\r\n                                   `step_4` = \"Straightlined 3 or more scales\",\r\n                                   `step_5` = \"Made repetitive pattern (e.g. AB-AB-AB, ABC-ABC-ABC) 50% or more of the time\",\r\n                                   `step_6` = \"Unrealistic responses to quantitative question set (e.g. hours per week)\",\r\n                                   `step_7` = \"Highly unusual responses to highly correlated items\",\r\n                                   `step_8` = \"\")) %>%\r\n    rename(`Reason for Flag` = last_dataframe)\r\n  \r\n  # Add \"flagged\" column to last_occurrence\r\n  last_occurrence$`Flagged for Low Effort?` <- ifelse(last_occurrence$`Reason for Flag` == \"\", \"No\", \"Yes\")\r\n  \r\n  #Reorder columns\r\n  last_occurrence <- last_occurrence %>%\r\n    select(unique_id, `Flagged for Low Effort?`, `Reason for Flag`)\r\n  \r\n  #Add to df based on unique_id and move it to front\r\n  df <- df %>%\r\n    left_join(last_occurrence, by = \"unique_id\") %>%\r\n    select(`Flagged for Low Effort?`, `Reason for Flag`, unique_id, everything())\r\n\r\n  assign(\"df\", df, envir = .GlobalEnv)\r\n  assign(\"step_1\", step_1, envir = .GlobalEnv)\r\n  assign(\"step_2\", step_2, envir = .GlobalEnv)\r\n  assign(\"step_3\", step_3, envir = .GlobalEnv)\r\n  assign(\"step_4\", step_4, envir = .GlobalEnv)\r\n  assign(\"step_5\", step_5, envir = .GlobalEnv)\r\n  assign(\"step_6\", step_6, envir = .GlobalEnv)\r\n  assign(\"step_7\", step_7, envir = .GlobalEnv)\r\n  assign(\"step_8\", step_8, envir = .GlobalEnv)\r\n  \r\n  \r\n  assign(\"step_3_values\", step_3_values, envir = .GlobalEnv)\r\n  assign(\"step_4_values\", step_4_values, envir = .GlobalEnv)\r\n  assign(\"step_5_values\", step_5_values, envir = .GlobalEnv)\r\n  assign(\"step_6_values\", step_6_values, envir = .GlobalEnv)\r\n  assign(\"step_7_values\", step_7_values, envir = .GlobalEnv)\r\n  #assign(\"z\", z, envir = .GlobalEnv)\r\n  \r\n  return(df)\r\n}\r\n\r\n","type":"text"},{"name":"library_functions.R","content":"# Mahad function (from careless package)\r\nmahad <- function(x, plot = TRUE, flag = FALSE, confidence = 0.99, na.rm = TRUE) {\r\n  if(na.rm == FALSE) {\r\n    if(any(is.na(x)) == TRUE) {stop(\"Some values are NA. Mahalanobis distance was not computed.\r\n                                      Use na.rm = TRUE to use available cases.\", call. = FALSE)}\r\n  }\r\n  \r\n  #Subfunction \"mahad\" (from psych package)\r\n  outlier <- \r\n    function(x,plot=TRUE,bad=5,na.rm=TRUE,xlab,ylab,...) {\r\n      if(missing(xlab)) xlab <- expression(\"Quantiles of \" * ~chi ^2)\r\n      if(missing(ylab)) ylab <- expression(\"Mahalanobis \" * D^2)\r\n      rn <- rownames(x)\r\n      nvar <- ncol(x)\r\n      n.obs <- nrow(x)\r\n      if(!is.matrix(x)) x <- as.matrix(x)\r\n      nvar <- ncol(x)\r\n      Sx <- cov(x,use=\"pairwise\")\r\n      Sx.inv <- solve(Sx)\r\n      # Mx <- colMeans(x,na.rm=na.rm)\r\n      # x <- sweep(x,2,Mx)\r\n      #x <- t(scale(t(x),scale=FALSE))\r\n      x <- scale(x,scale=FALSE)\r\n      D2 <- t(apply(x,1,function(xx) colSums(xx * Sx.inv,na.rm=TRUE)))\r\n      D2 <- rowSums(D2*x,na.rm=TRUE)\r\n      names(D2) <- rn\r\n      \r\n      if(plot) {\r\n        Chi2 <- qchisq(ppoints(n.obs), df =  nvar)\r\n        qqplot(Chi2, D2,\r\n               main = expression(\"Q-Q plot of Mahalanobis\" * ~D^2 *\r\n                                   \" vs. quantiles of\" * ~ chi[nvar]^2),xlab=xlab,ylab=ylab,...)\r\n        abline(0, 1, col = 'gray')\r\n        worst <- order(D2,decreasing=TRUE)\r\n        text(Chi2[n.obs:(n.obs-bad+1)],D2[worst[1:bad]],names(D2)[worst[1:bad]],pos=3,...)\r\n      }\r\n      return(D2)\r\n    }\r\n  \r\n  #remove rows with all NA and issue warning\r\n  complete.na <- apply(x, 1, function(y) { all(is.na(y)) } )\r\n  if(any(complete.na)) {\r\n    warning(\"Some cases contain only NA values. The Mahalanobis distance will be calculated using available cases.\",\r\n            call. = FALSE) }\r\n  x_filtered <- x[!complete.na,]\r\n  \r\n  maha_data <- as.numeric(outlier(x_filtered, plot, bad = 0, na.rm = na.rm))\r\n  d_sq <- rep_len(NA, nrow(x_filtered))\r\n  d_sq[!complete.na] <- maha_data\r\n  \r\n  if(flag == TRUE) {\r\n    cut <- stats::qchisq(confidence, ncol(x))\r\n    flagged <- (d_sq > cut)\r\n    return(data.frame(d_sq = d_sq, flagged = flagged))\r\n  }\r\n  else{ return(d_sq) }\r\n}\r\n\r\n# IRV function (from careless package)\r\nirv <- function(x, na.rm = TRUE, split = FALSE, num.split = 3) {\r\n  out <- apply(x, 1, stats::sd, na.rm = na.rm)\r\n  \r\n  if(split == TRUE) {\r\n    chunk <- function(x,n) split(x, cut(seq_along(x), n, labels = FALSE))\r\n    split_x <- apply(x, 1, chunk, num.split)\r\n    out_split <- t(replicate(nrow(x), rep(NA, num.split)))\r\n    colnames(out_split) <- paste0(\"irv\",1:num.split)\r\n    for(k in 1:nrow(out_split)) {\r\n      split_x_single <- split_x[[k]]\r\n      out_split[k,] <- unlist(lapply(split_x_single, stats::sd, na.rm = na.rm), use.names = FALSE)\r\n    }\r\n    out_split <- data.frame(out, out_split)\r\n    colnames(out_split)[1] <- \"irvTotal\"\r\n    return(out_split)} else { #split subsection end\r\n      return(out)\r\n    }\r\n}\r\n\r\n# Longstring function (from careless package)\r\nlongstring <- function(x, avg=FALSE) {\r\n  \r\n  # subfunction that calculates the length of consecutive identical responses\r\n  rle_string <- function(x) {\r\n    rle_list <- rle(x)\r\n    longstr <- max(rle_list$lengths)\r\n    avgstr <- mean(rle_list$lengths)\r\n    return(cbind(longstr, avgstr))\r\n  }\r\n  \r\n  # apply the subfunctions to each row (case, subject)\r\n  output <- apply(x, 1, rle_string)\r\n  output <- data.frame(t(output))\r\n  colnames(output) <- (c('longstr','avgstr'))\r\n  \r\n  if(avg == TRUE) {\r\n    return(output)\r\n  } else {\r\n    return(output[,'longstr'])\r\n  }\r\n}\r\n\r\n#Longstring number of times 7 or more consecutive identical responses (modified from longstring in careless package)\r\nlongstring_n_times <- function(x, avg=FALSE, threshold=6) {\r\n  \r\n  # subfunction that calculates the length of consecutive identical responses\r\n  rle_string <- function(x) {\r\n    rle_list <- rle(x)\r\n    longstr <- max(rle_list$lengths)\r\n    avgstr <- mean(rle_list$lengths)\r\n    count_longstr <- sum(rle_list$lengths > threshold)\r\n    return(cbind(longstr, avgstr, count_longstr))\r\n  }\r\n  \r\n  # apply the subfunctions to each row (case, subject)\r\n  output <- apply(x, 1, rle_string)\r\n  output <- data.frame(t(output))\r\n  colnames(output) <- c('longstr','avgstr', 'count_longstr')\r\n  \r\n  if(avg == TRUE) {\r\n    return(output)\r\n  } else {\r\n    return(output[, c('longstr', 'count_longstr')])\r\n  }\r\n}\r\n\r\n# Psych synonyms function (from careless package)\r\npsychsyn <- function(x, critval=.60, anto=FALSE, diag=FALSE, resample_na=TRUE) {\r\n  x <- as.matrix(x)\r\n  item_pairs <- get_item_pairs(x, critval, anto)\r\n  \r\n  synonyms <- apply(x,1,syn_for_one, item_pairs, resample_na)\r\n  synonyms_df <- as.data.frame(aperm(synonyms))\r\n  colnames(synonyms_df) <- c(\"numPairs\", \"cor\")\r\n  \r\n  if(diag==TRUE) { return(synonyms_df) }\r\n  else { return(synonyms_df$cor) }\r\n}\r\n\r\n# Helper function that identifies psychometric synonyms in a given dataset\r\nget_item_pairs <- function(x, critval=.60, anto=FALSE) {\r\n  critval <- abs(critval) #Dummy Proofing\r\n  \r\n  correlations <- stats::cor(x, use = \"pairwise.complete.obs\")\r\n  correlations[upper.tri(correlations, diag=TRUE)] <- NA\r\n  correlations <- as.data.frame(as.table(correlations))\r\n  \r\n  # Identifying item pairs differs depending on whether the user wants\r\n  # Psychometric Synonyms or Psychometric Antonyms\r\n  if(anto==FALSE) {\r\n    item_pair_names <- correlations[which(correlations$Freq > critval, arr.ind=TRUE),c(1,2)]\r\n    if(nrow(item_pair_names)==0) {\r\n      stop(\"No Psychometric Synonyms found.\")\r\n    }\r\n  }\r\n  else if(anto==TRUE) {\r\n    item_pair_names <- correlations[which(correlations$Freq < -critval, arr.ind=TRUE),c(1,2)]\r\n    if(nrow(item_pair_names)==0) {\r\n      stop(\"No Psychometric Antonyms found.\")\r\n    }\r\n  }\r\n  \r\n  matches <- item_pair_names\r\n  return(matches)\r\n}\r\n\r\n# Helper function to calculate the within person correlation for a single individual\r\nsyn_for_one <- function(x, item_pairs, resample_na) {\r\n  item_pairs_omit_na <- which(!(is.na(x[item_pairs[,1]]) | is.na(x[item_pairs[,2]])))\r\n  sum_item_pairs <- length(item_pairs_omit_na)\r\n  #only execute if more than two item pairs\r\n  if(sum_item_pairs > 2) {\r\n    itemvalues <- cbind(as.numeric(x[as.numeric(item_pairs[,1])]), as.numeric(x[as.numeric(item_pairs[,2])]))\r\n    \r\n    # helper that calculates within-person correlation\r\n    psychsyn_cor <- function(x) {\r\n      suppressWarnings(stats::cor(x, use = \"pairwise.complete.obs\", method = \"pearson\")[1,2])\r\n    }\r\n    \r\n    # if resample_na == TRUE, re-calculate psychsyn should a result return NA\r\n    if(resample_na == TRUE) {\r\n      counter <- 1\r\n      synvalue <- psychsyn_cor(itemvalues)\r\n      while(counter <= 10 & is.na(synvalue)) {\r\n        itemvalues <- t(apply(itemvalues, 1, sample, 2, replace = F))\r\n        synvalue <- psychsyn_cor(itemvalues)\r\n        counter = counter+1\r\n      }\r\n    } else {\r\n      synvalue <- psychsyn_cor(itemvalues) # executes if resample_na == FALSE\r\n    }\r\n    \r\n  } else {synvalue <- NA} # executes if insufficient item pairs\r\n  \r\n  return(c(sum_item_pairs, synvalue))\r\n}","type":"text"}]
